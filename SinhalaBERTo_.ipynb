{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nuwantha97/Sinhala_spell_and_grammer_checker/blob/Notebooks/SinhalaBERTo_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eatndB-ujXeZ",
        "outputId": "9ac8dd06-1e32-4b93-aa05-e8e378683c06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 1"
      ],
      "metadata": {
        "id": "K-1az-9gkYa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein"
      ],
      "metadata": {
        "id": "xWP50d7JjaqH",
        "outputId": "9b26fe96-98bc-4fbe-9321-308fb78e93af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.26.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting Levenshtein==0.26.1 (from python-Levenshtein)\n",
            "  Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.26.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading python_Levenshtein-0.26.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.26.1 python-Levenshtein-0.26.1 rapidfuzz-3.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the input text file in read mode\n",
        "with open('/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_full_word_list_2016-10-08.txt', 'r', encoding='utf-8') as infile:\n",
        "    # Read all lines from the input file\n",
        "    lines = infile.readlines()\n",
        "\n",
        "# Create a list to store all words\n",
        "words = []\n",
        "\n",
        "# Loop through each line to extract words\n",
        "for line in lines:\n",
        "    # Split the line into words and extend the list\n",
        "    words.extend(line.split())\n"
      ],
      "metadata": {
        "id": "0vtWv1EmjeLD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_words = []\n",
        "seen = set()\n",
        "for word in words:\n",
        "    if word not in seen:\n",
        "        unique_words.append(word)\n",
        "        seen.add(word)"
      ],
      "metadata": {
        "id": "WdahcJQAjn2u"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Sinhala Unicode character range\n",
        "sinhala_pattern = re.compile(r'^[\\u0D80-\\u0DFF]+$')\n",
        "\n",
        "# Filter Sinhala words\n",
        "sinhala_words = [word for word in unique_words if sinhala_pattern.match(word)]"
      ],
      "metadata": {
        "id": "be3UfYGNjqfp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Open the output CSV file in write mode\n",
        "with open('/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict1.csv', 'w', encoding='utf-8', newline='') as outfile:\n",
        "    writer = csv.writer(outfile)\n",
        "\n",
        "    # Write each word as a new row in the CSV\n",
        "    for word in sinhala_words:\n",
        "        writer.writerow([word])\n",
        "\n",
        "print(\"Words have been written to 'sinhala_dict1.csv' line by line.\")\n"
      ],
      "metadata": {
        "id": "rhVBArYYjsve",
        "outputId": "53e92907-a445-46e9-d725-06308f144a27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words have been written to 'sinhala_dict1.csv' line by line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 2"
      ],
      "metadata": {
        "id": "szt_hmUVkTfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the .xlsx file\n",
        "file_path = \"/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/data-spell-checker.xlsx\"  # Replace with your file's path\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Filter the rows where label == 1\n",
        "filtered_data = data[data['label'] == 1]\n",
        "\n",
        "# Select only the words column\n",
        "words_with_label_1 = filtered_data['word']\n",
        "\n",
        "# Save the filtered words to a .csv file\n",
        "output_file_path = \"/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict2.csv\"  # Replace with your desired output file name\n",
        "words_with_label_1.to_csv(output_file_path, index=False, header=False)\n",
        "\n",
        "print(f\"Filtered words saved to {output_file_path}\")\n"
      ],
      "metadata": {
        "id": "aAEm-fqHkO6P",
        "outputId": "5fe9eaf9-da2a-4978-db46-42cd5e9e9717",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered words saved to /content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: unique words in sinhala_dict1.csv and sinhala_dict2.csv files add to sinhala_dictFinal.csv\n",
        "\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "def merge_csv_unique_words(file1, file2, output_file):\n",
        "    \"\"\"\n",
        "    Merges two CSV files, keeping only unique Sinhala words.\n",
        "\n",
        "    Args:\n",
        "        file1: Path to the first CSV file.\n",
        "        file2: Path to the second CSV file.\n",
        "        output_file: Path to the output CSV file.\n",
        "    \"\"\"\n",
        "\n",
        "    unique_words = set()\n",
        "\n",
        "    try:\n",
        "        with open(file1, 'r', encoding='utf-8') as f1:\n",
        "            reader1 = csv.reader(f1)\n",
        "            for row in reader1:\n",
        "                if row and row[0]:  # Check for empty rows and empty strings.\n",
        "                  unique_words.add(row[0])\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: {file1} not found.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "      with open(file2, 'r', encoding='utf-8') as f2:\n",
        "          reader2 = csv.reader(f2)\n",
        "          for row in reader2:\n",
        "              if row and row[0]:\n",
        "                  unique_words.add(row[0])\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: {file2} not found.\")\n",
        "        return\n",
        "\n",
        "    # Write unique words to the output file\n",
        "    try:\n",
        "      with open(output_file, 'w', encoding='utf-8', newline='') as outfile:\n",
        "          writer = csv.writer(outfile)\n",
        "          for word in unique_words:\n",
        "              writer.writerow([word])\n",
        "      print(f\"Unique words merged and saved to {output_file}\")\n",
        "    except Exception as e:\n",
        "      print(f\"An error occurred while writing to the output file: {e}\")\n",
        "\n",
        "\n",
        "# Example usage (replace with your file paths):\n",
        "file1_path = '/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict1.csv'\n",
        "file2_path = '/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict2.csv'\n",
        "output_file_path = '/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dictFinal.csv'\n",
        "\n",
        "\n",
        "merge_csv_unique_words(file1_path, file2_path, output_file_path)"
      ],
      "metadata": {
        "id": "NDxd20uzkg_P",
        "outputId": "88d5fce9-94cf-4b68-a689-9eb75656d96e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique words merged and saved to /content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dictFinal.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: load sinhala_dictFinal.csv and print sample\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv('/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dictFinal.csv', header=None, names=['word'])\n",
        "\n",
        "# Print the first 10 words as a sample\n",
        "print(df.sample(30))"
      ],
      "metadata": {
        "id": "5_gXw2XllIrV",
        "outputId": "7d8e25d8-c7d6-458c-95ce-695fd86d483f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    word\n",
            "73883               මෙහි\n",
            "73892              සලකනත\n",
            "8814              හැක්කී\n",
            "23364              ස්ථූප\n",
            "13531             සත්භාව\n",
            "85639             නාරස්න\n",
            "10398          ත්‍රිපාදය\n",
            "22108           ගොවිතැනට\n",
            "56944              වැරීම\n",
            "61298              රූධිය\n",
            "51965           හස්තිපති\n",
            "35449      සුරංගනාවියන්ට\n",
            "85125          ප්‍රකාශණය\n",
            "27564          ස්කන්දාර්\n",
            "82824            සොටුවත්\n",
            "25559  සැන්ප්‍රැන්සිස්කො\n",
            "86459         රසගැන්වීමට\n",
            "75839              සමරවු\n",
            "53143            සිටියේය\n",
            "71104            සෙබෙවති\n",
            "23980              සිතමි\n",
            "51195            බුබුළුව\n",
            "65476             ඩෙමැලය\n",
            "15229          පූර්වගමනය\n",
            "40497            හාදයෙක්\n",
            "9839            කුන්දුන්\n",
            "30293              සැලීම\n",
            "77432            කටුකුටු\n",
            "32169       හබ්යරිමානාගේ\n",
            "53914        සේවායුක්තයා\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sinhala_to_ipa(text):\n",
        "    consonant_map = {\n",
        "        \"ක\": \"k\", \"ඛ\": \"kʰ\", \"ග\": \"ɡ\", \"ඝ\": \"ɡʱ\",\n",
        "        \"ඞ\": \"ŋ\", \"ඟ\": \"ŋɡ\", \"ච\": \"ʧ\", \"ඡ\": \"ʧʰ\",\n",
        "        \"ජ\": \"ʤ\", \"ඣ\": \"ʤʱ\", \"ඤ\": \"ɲ\", \"ඥ\": \"ɡn\",\n",
        "        \"ට\": \"ʈ\", \"ඨ\": \"ʈʰ\", \"ඩ\": \"ɖ\", \"ඪ\": \"ɖʱ\",\n",
        "        \"ණ\": \"ɳ\", \"ත\": \"t̪\", \"ථ\": \"t̪ʰ\", \"ද\": \"d̪\",\n",
        "        \"ධ\": \"d̪ʱ\", \"න\": \"n̪\", \"ප\": \"p\", \"ඵ\": \"pʰ\",\n",
        "        \"බ\": \"b\", \"භ\": \"bʱ\", \"ම\": \"m\", \"ය\": \"j\",\n",
        "        \"ර\": \"r\", \"ල\": \"l\", \"ව\": \"ʋ\", \"ශ\": \"ʃ\",\n",
        "        \"ෂ\": \"ʂ\", \"ස\": \"s\", \"හ\": \"h\", \"ළ\": \"ɭ\",\n",
        "        \"ෆ\": \"f\"\n",
        "    }\n",
        "\n",
        "    vowel_map = {\n",
        "        \"අ\": \"ʌ\", \"ආ\": \"aː\", \"ඇ\": \"æ\", \"ඈ\": \"æː\",\n",
        "        \"ඉ\": \"i\", \"ඊ\": \"iː\", \"උ\": \"u\", \"ඌ\": \"uː\",\n",
        "        \"එ\": \"e\", \"ඒ\": \"eː\", \"ඔ\": \"o\", \"ඕ\": \"oː\",\n",
        "        \"ා\": \"aː\", \"ැ\": \"æ\", \"ෑ\": \"æː\", \"ි\": \"i\",\n",
        "        \"ී\": \"iː\", \"ු\": \"u\", \"ූ\": \"uː\", \"ෙ\": \"e\",\n",
        "        \"ේ\": \"eː\", \"ො\": \"o\", \"ෝ\": \"oː\", \"ෞ\": \"au\"\n",
        "    }\n",
        "\n",
        "    def get_next_chars(pos, text, count=3):\n",
        "        result = []\n",
        "        for i in range(count):\n",
        "            if pos + i < len(text):\n",
        "                result.append(text[pos + i])\n",
        "            else:\n",
        "                result.append(None)\n",
        "        return result\n",
        "\n",
        "    def process_syllable(pos, text):\n",
        "        char = text[pos]\n",
        "        next_chars = get_next_chars(pos + 1, text)\n",
        "\n",
        "        if char == \" \":\n",
        "            return \"| \", 1\n",
        "\n",
        "        if char == \"අ\" and next_chars[0] == \"ං\":\n",
        "            return \"ʌŋ \", 2\n",
        "\n",
        "        if char == \"ං\":\n",
        "            return \"\", 1\n",
        "\n",
        "        if char in consonant_map:\n",
        "            if char == \"න\" and pos + 2 < len(text) and text[pos:pos+3] == \"නවා\":\n",
        "                return \"n̪ ə \", 1\n",
        "\n",
        "            if char == \"ව\" and pos + 1 < len(text) and text[pos:pos+2] == \"වා\":\n",
        "                return \"ʋ a \", 2\n",
        "\n",
        "            base = consonant_map[char] + \" \"\n",
        "\n",
        "            if next_chars[0] in vowel_map:\n",
        "                return base, 1\n",
        "            elif next_chars[0] == \"්\":\n",
        "                return base, 2\n",
        "            elif pos == len(text) - 1:\n",
        "                return base + \"ə \", 1\n",
        "            else:\n",
        "                if char == \"ක\" and pos == 1:\n",
        "                    return base + \"ʌ \", 1\n",
        "                else:\n",
        "                    return base + \"ʌ \", 1\n",
        "\n",
        "        elif char in vowel_map:\n",
        "            if char == \"ා\" and pos == len(text) - 1:\n",
        "                return \"\", 1\n",
        "            return vowel_map[char] + \" \", 1\n",
        "\n",
        "        elif char == \"්\":\n",
        "            return \"\", 1\n",
        "\n",
        "        return char + \" \", 1\n",
        "\n",
        "    result = \"\"\n",
        "    i = 0\n",
        "    while i < len(text):\n",
        "        segment, skip = process_syllable(i, text)\n",
        "        result += segment\n",
        "        i += skip\n",
        "\n",
        "    result = result.strip()\n",
        "    while \"  \" in result:\n",
        "        result = result.replace(\"  \", \" \")\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "Ip6lbp1OmDoI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset without headers (it doesn't have column names)\n",
        "file_path = '/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dictFinal.csv'\n",
        "df = pd.read_csv(file_path, header=None, names=['word'])\n",
        "\n",
        "# Apply the `sinhala_to_ipa` function to each word\n",
        "df['IPA'] = df['word'].apply(sinhala_to_ipa)\n",
        "\n",
        "# Save the new dataset with 'word' and 'IPA' columns to a new CSV file\n",
        "output_path = '/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict_with_ipa.csv'\n",
        "df[['word', 'IPA']].to_csv(output_path, index=False)\n",
        "\n",
        "print(\"New dataset with IPA has been saved to:\", output_path)\n"
      ],
      "metadata": {
        "id": "QRnyUcY4mdJn",
        "outputId": "693712c8-3c78-4113-dd87-991953a12c62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New dataset with IPA has been saved to: /content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict_with_ipa.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "PfyfEjesmrye",
        "outputId": "907cde2e-d91e-4aa7-815c-949305fc517d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           word                      IPA\n",
              "0      වාතජ්වරය   ʋ a t̪ ʌ ʤ ʋ ʌ r ʌ j ə\n",
              "1         සංකූල             s ʌ k uː l ə\n",
              "2         ගනරන්          ɡ ʌ n̪ ʌ r ʌ n̪\n",
              "3           කරේ                 k ʌ r eː\n",
              "4      හත්සීයකට  h ʌ t̪ s iː j ʌ k ʌ ʈ ə\n",
              "...         ...                      ...\n",
              "93840    සත්තකය      s ʌ t̪ t̪ ʌ k ʌ j ə\n",
              "93841   දෙගුණකය     d̪ e ɡ u ɳ ʌ k ʌ j ə\n",
              "93842   සොමිනස්           s o m i n̪ ʌ s\n",
              "93843     ඩයිකය          ɖ ʌ j i k ʌ j ə\n",
              "93844   තේරෙනවා       t̪ eː r e n̪ ə ʋ a\n",
              "\n",
              "[93845 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cad3ffcb-153b-4732-8878-9a709b60cc9b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>IPA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>වාතජ්වරය</td>\n",
              "      <td>ʋ a t̪ ʌ ʤ ʋ ʌ r ʌ j ə</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>සංකූල</td>\n",
              "      <td>s ʌ k uː l ə</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ගනරන්</td>\n",
              "      <td>ɡ ʌ n̪ ʌ r ʌ n̪</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>කරේ</td>\n",
              "      <td>k ʌ r eː</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>හත්සීයකට</td>\n",
              "      <td>h ʌ t̪ s iː j ʌ k ʌ ʈ ə</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93840</th>\n",
              "      <td>සත්තකය</td>\n",
              "      <td>s ʌ t̪ t̪ ʌ k ʌ j ə</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93841</th>\n",
              "      <td>දෙගුණකය</td>\n",
              "      <td>d̪ e ɡ u ɳ ʌ k ʌ j ə</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93842</th>\n",
              "      <td>සොමිනස්</td>\n",
              "      <td>s o m i n̪ ʌ s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93843</th>\n",
              "      <td>ඩයිකය</td>\n",
              "      <td>ɖ ʌ j i k ʌ j ə</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93844</th>\n",
              "      <td>තේරෙනවා</td>\n",
              "      <td>t̪ eː r e n̪ ə ʋ a</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>93845 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cad3ffcb-153b-4732-8878-9a709b60cc9b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cad3ffcb-153b-4732-8878-9a709b60cc9b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cad3ffcb-153b-4732-8878-9a709b60cc9b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-99412ce8-3d50-47bb-b2f7-32d8ab59c524\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-99412ce8-3d50-47bb-b2f7-32d8ab59c524')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-99412ce8-3d50-47bb-b2f7-32d8ab59c524 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4e3c1ff5-c1f6-426f-99db-6cd8bc14ec11\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4e3c1ff5-c1f6-426f-99db-6cd8bc14ec11 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 93845,\n  \"fields\": [\n    {\n      \"column\": \"word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 93845,\n        \"samples\": [\n          \"\\u0dc3\\u0ddc\\u0dc4\\u0ddc\\u0dba\\u0dd4\\u0dbb\\u0dd2\\u0db1\\u0dca\",\n          \"\\u0dbb\\u0dad\\u0dca\\u0db1\\u0dd2\\u0dba\",\n          \"\\u0d85\\u0db4\\u0dd2\\u0dbb\\u0dd2\\u0dc3\\u0dd2\\u0daf\\u0dd4\\u0dad\\u0dcf\\u0dc0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IPA\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 93303,\n        \"samples\": [\n          \"n\\u032a o s o s\",\n          \"s e\\u02d0 n\\u032a \\u028c k \\u028c t\\u032a\",\n          \"s a\\u02d0 p p u k a\\u02d0 r \\u028c j a\\u02d0 \\u0261 e\\u02d0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def findCorrectWord(dict,ipaWord):\n",
        "  for index, row in dict.iterrows():\n",
        "    if row['IPA'] == ipaWord:\n",
        "      return row['word']"
      ],
      "metadata": {
        "id": "SsOm7u2rnLtN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import Levenshtein\n",
        "\n",
        "def spell_check(word, dictionary, top_n=3):\n",
        "    # List to store words with their distances\n",
        "    word_distances = []\n",
        "\n",
        "    for correct_word in dictionary:\n",
        "        # Calculate the Levenshtein distance between the word and dictionary word\n",
        "        distance = Levenshtein.distance(word, correct_word)\n",
        "        word_distances.append((correct_word, distance))\n",
        "\n",
        "    # Sort the list by distance (ascending order)\n",
        "    word_distances.sort(key=lambda x: x[1])\n",
        "\n",
        "    # Return the top N closest words\n",
        "    return word_distances[:top_n]\n",
        "\n",
        "def check_sentence(sentence, sinhala_dictionary):\n",
        "    words = sentence.split()  # Split the input sentence into words\n",
        "    corrected_words = []  # List to store corrected words\n",
        "    distances = []  # List to store Levenshtein distances for each word\n",
        "\n",
        "    for word in words:\n",
        "        # Get the top suggestion (closest word) and its distance\n",
        "        top_words = spell_check(sinhala_to_ipa(word), sinhala_dictionary, top_n=1)\n",
        "        if top_words:  # Ensure there's at least one suggestion\n",
        "            corrected_word, distance = top_words[0]  # Top suggestion\n",
        "            corrected_words.append(findCorrectWord(df,corrected_word))  # Add corrected word\n",
        "            distances.append(distance)  # Add the distance\n",
        "        else:\n",
        "            # If no suggestions, append the original word\n",
        "            corrected_words.append(word)\n",
        "            distances.append(None)  # No distance available\n",
        "\n",
        "        print_suggestion(word, top_words)\n",
        "\n",
        "    # Combine corrected words into a single sentence\n",
        "    corrected_sentence = ' '.join(corrected_words)\n",
        "\n",
        "    # Return values\n",
        "    return sentence, corrected_sentence, distances\n",
        "\n",
        "def print_suggestion(word, top_words):\n",
        "    top_words = [(findCorrectWord(df,correct_word), distance) for correct_word, distance in top_words]\n",
        "    print(f\"Suggestions for '{word}':\")\n",
        "    for i, (correct_word, distance) in enumerate(top_words, 1):\n",
        "        print(f\"{i}. {correct_word} (Distance: {distance})\")"
      ],
      "metadata": {
        "id": "R4Lgscu4nMYp"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def load_dictionary(file_path):\n",
        "  df = pd.read_csv(file_path)\n",
        "  return df"
      ],
      "metadata": {
        "id": "cUFcC_rrnPHl"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dictionary from the text file\n",
        "sinhala_dictionary = load_dictionary('/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict_with_ipa.csv')\n",
        "\n",
        "# Input word\n",
        "#sentence = \"මම දනපත දිනපටා ලියනවා\"\n",
        "sentence = \"මම පොත් ලයනවා\"\n",
        "\n",
        "# Perform spell check\n",
        "sentence, corrected_sentence, distances = check_sentence(sentence, sinhala_dictionary['IPA'])\n",
        "print(f\"\\nInput Sentence: {sentence}\")\n",
        "print(f\"Suggested Correction: {corrected_sentence}\")\n",
        "print(f\"Levenshtein Distances: {distances}\")"
      ],
      "metadata": {
        "id": "pxZyP-NGnwme",
        "outputId": "605bbbf9-58d4-4cf0-a1a2-2644bb0f041b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suggestions for 'මම':\n",
            "1. මම (Distance: 0)\n",
            "2. මඩ (Distance: 1)\n",
            "3. මර (Distance: 1)\n",
            "Suggestions for 'පොත්':\n",
            "1. පොත් (Distance: 0)\n",
            "2. සොතා (Distance: 1)\n",
            "3. පුතා (Distance: 1)\n",
            "Suggestions for 'ලයනවා':\n",
            "1. ලබනවා (Distance: 1)\n",
            "2. වයනවා (Distance: 1)\n",
            "3. ලියනවා (Distance: 1)\n",
            "\n",
            "Input Sentence: මම පොත් ලයනවා\n",
            "Suggested Correction: මම පොත් ලබනවා\n",
            "Levenshtein Distances: [0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dictionary from the text file\n",
        "sinhala_dictionary = load_dictionary('/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict_with_ipa.csv')\n",
        "\n",
        "# Input word\n",
        "sentence = \"මම සල්ලම් කරන්න යනවා\"\n",
        "\n",
        "# Perform spell check\n",
        "sentence, corrected_sentence, distances = check_sentence(sentence, sinhala_dictionary['IPA'])\n",
        "\n",
        "# Add <mask> for words with distance > 0\n",
        "masked_sentence = ' '.join([f'<mask>' if dist > 0 else word for word, dist in zip(sentence.split(), distances)])\n",
        "\n",
        "print(f\"\\nInput Sentence: {sentence}\")\n",
        "print(f\"Suggested Correction: {corrected_sentence}\")\n",
        "print(f\"Masked Sentence: {masked_sentence}\")\n",
        "print(f\"Levenshtein Distances: {distances}\")"
      ],
      "metadata": {
        "id": "BED94mvBqyoc",
        "outputId": "3c8a7468-e5ab-4d25-c1dd-124f1011ecb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suggestions for 'මම':\n",
            "1. මම (Distance: 0)\n",
            "Suggestions for 'සල්ලම්':\n",
            "1. සල්ලම් (Distance: 0)\n",
            "Suggestions for 'කරන්න':\n",
            "1. කරන්න (Distance: 0)\n",
            "Suggestions for 'යනවා':\n",
            "1. යනවා (Distance: 0)\n",
            "\n",
            "Input Sentence: මම සල්ලම් කරන්න යනවා\n",
            "Suggested Correction: මම සල්ලම් කරන්න යනවා\n",
            "Masked Sentence: මම සල්ලම් කරන්න යනවා\n",
            "Levenshtein Distances: [0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SinhalaBERTo_"
      ],
      "metadata": {
        "id": "iC9AVUUWjUtw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR7jfHc0SfDE",
        "outputId": "4e9e55bb-191f-493a-c5c4-40645e0a9855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/modeling_auto.py:1838: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.13394880294799805,\n",
              "  'token': 1237,\n",
              "  'token_str': ' ආදරය',\n",
              "  'sequence': 'මම ආදරය කරන්න යනවා'},\n",
              " {'score': 0.10711520165205002,\n",
              "  'token': 498,\n",
              "  'token_str': ' ඒක',\n",
              "  'sequence': 'මම ඒක කරන්න යනවා'},\n",
              " {'score': 0.07514398545026779,\n",
              "  'token': 446,\n",
              "  'token_str': ' මම',\n",
              "  'sequence': 'මම මම කරන්න යනවා'},\n",
              " {'score': 0.06738491356372833,\n",
              "  'token': 1190,\n",
              "  'token_str': ' අමතක',\n",
              "  'sequence': 'මම අමතක කරන්න යනවා'},\n",
              " {'score': 0.028392260894179344,\n",
              "  'token': 1030,\n",
              "  'token_str': ' බය',\n",
              "  'sequence': 'මම බය කරන්න යනවා'}]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelWithLMHead, pipeline\n",
        "\n",
        "model = AutoModelWithLMHead.from_pretrained(\"keshan/SinhalaBERTo\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"keshan/SinhalaBERTo\")\n",
        "\n",
        "fill_mask = pipeline('fill-mask', model=model, tokenizer=tokenizer)\n",
        "\n",
        "fill_mask(masked_sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: I need to print most scored sequence as corrected sentence and other 2 as suggestions from fill_mask\n",
        "\n",
        "def print_top_suggestions(sentence, top_suggestions):\n",
        "    print(f\"Input Sentence: {sentence}\")\n",
        "    print(f\"Corrected Sentence: {top_suggestions[0]['sequence']}\")\n",
        "    print(\"Suggestions:\")\n",
        "    for i, suggestion in enumerate(top_suggestions[1:]):  # Skip the top suggestion as it's already printed\n",
        "      print(f\"{i+1}. {suggestion['sequence']}\")\n",
        "\n",
        "# Example usage:\n",
        "sentence = masked_sentence  # Replace with your sentence\n",
        "top_suggestions = fill_mask(sentence)\n",
        "print_top_suggestions(sentence, top_suggestions)"
      ],
      "metadata": {
        "id": "f4eix0-mVGYy",
        "outputId": "e7a0e4ed-60dc-40dd-8e7f-939352cacc59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sentence: මම <mask> කරන්න යනවා\n",
            "Corrected Sentence: මම ආදරය කරන්න යනවා\n",
            "Suggestions:\n",
            "1. මම ඒක කරන්න යනවා\n",
            "2. මම මම කරන්න යනවා\n",
            "3. මම අමතක කරන්න යනවා\n",
            "4. මම බය කරන්න යනවා\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelWithLMHead, pipeline\n",
        "import itertools\n",
        "\n",
        "def handle_multiple_masks(text, model, tokenizer, top_k=3):\n",
        "    \"\"\"\n",
        "    Handle multiple masks in a sentence by generating all possible combinations\n",
        "    \"\"\"\n",
        "    # Create fill-mask pipeline\n",
        "    fill_mask = pipeline('fill-mask', model=model, tokenizer=tokenizer)\n",
        "\n",
        "    # Get all masked positions\n",
        "    mask_token = tokenizer.mask_token\n",
        "    mask_positions = [i for i, word in enumerate(text.split()) if word == mask_token]\n",
        "\n",
        "    if len(mask_positions) == 0:\n",
        "        return [{\"sequence\": text, \"score\": 1.0}]\n",
        "\n",
        "    # Get predictions for each mask position\n",
        "    all_predictions = []\n",
        "\n",
        "    for position in mask_positions:\n",
        "        predictions = fill_mask(text)\n",
        "        # Take only top_k predictions\n",
        "        predictions = predictions[:top_k]\n",
        "        # Extract just the token_str and score from each prediction\n",
        "        # Modified to handle different prediction format\n",
        "        processed_predictions = [\n",
        "            {'token_str': p[0]['token_str'].strip(), 'score': float(p[0]['score'])} if isinstance(p, list) else\n",
        "            {'token_str': p['token_str'].strip(), 'score': float(p['score'])}\n",
        "            for p in predictions\n",
        "        ]\n",
        "        all_predictions.append(processed_predictions)\n",
        "\n",
        "    # Generate all possible combinations\n",
        "    all_combinations = list(itertools.product(*all_predictions))\n",
        "\n",
        "    results = []\n",
        "    for combination in all_combinations:\n",
        "        # Create a new sentence with the predicted words\n",
        "        words = text.split()\n",
        "        total_score = 1.0\n",
        "        mask_idx = 0\n",
        "\n",
        "        for i in range(len(words)):\n",
        "            if words[i] == mask_token:\n",
        "                prediction = combination[mask_idx]\n",
        "                words[i] = prediction['token_str']\n",
        "                total_score *= prediction['score']\n",
        "                mask_idx += 1\n",
        "\n",
        "        complete_sentence = ' '.join(words)\n",
        "        results.append({\n",
        "            \"sequence\": complete_sentence,\n",
        "            \"score\": total_score\n",
        "        })\n",
        "\n",
        "    # Sort results by score\n",
        "    results.sort(key=lambda x: x['score'], reverse=True)\n",
        "    return results\n",
        "\n",
        "# Example usage\n",
        "model = AutoModelWithLMHead.from_pretrained(\"keshan/SinhalaBERTo\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"keshan/SinhalaBERTo\")\n",
        "\n",
        "# Example with multiple masks\n",
        "text = \"ඉතා වේගයෙන් <mask> ගන්නා <mask> එහි ඉදිරිපස රෝදය ඉහලට ඔසවයි.\"\n",
        "\n",
        "# Get and print results\n",
        "results = handle_multiple_masks(text, model, tokenizer, top_k=3)\n",
        "\n",
        "print(\"\\nTop 5 combinations:\")\n",
        "for i, result in enumerate(results[:5]):\n",
        "    print(f\"\\nOption {i+1}:\")\n",
        "    print(f\"Sequence: {result['sequence']}\")\n",
        "    print(f\"Confidence Score: {result['score']:.4f}\")"
      ],
      "metadata": {
        "id": "z0q9UjTXydQc",
        "outputId": "663fe336-8768-4b6b-bbc0-8b961276fe1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/modeling_auto.py:1838: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 5 combinations:\n",
            "\n",
            "Option 1:\n",
            "Sequence: ඉතා වේගයෙන් අතර ගන්නා අතර එහි ඉදිරිපස රෝදය ඉහලට ඔසවයි.\n",
            "Confidence Score: 0.1827\n",
            "\n",
            "Option 2:\n",
            "Sequence: ඉතා වේගයෙන් ජය ගන්නා අතර එහි ඉදිරිපස රෝදය ඉහලට ඔසවයි.\n",
            "Confidence Score: 0.0420\n",
            "\n",
            "Option 3:\n",
            "Sequence: ඉතා වේගයෙන් අතර ගන්නා ජය එහි ඉදිරිපස රෝදය ඉහලට ඔසවයි.\n",
            "Confidence Score: 0.0420\n",
            "\n",
            "Option 4:\n",
            "Sequence: ඉතා වේගයෙන් ජය ගන්නා ජය එහි ඉදිරිපස රෝදය ඉහලට ඔසවයි.\n",
            "Confidence Score: 0.0097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6hvZhh5l7B6-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}