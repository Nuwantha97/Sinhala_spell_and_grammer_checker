{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMct34hLQeNwppyFQVtHzh/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nuwantha97/Sinhala_spell_and_grammer_checker/blob/Notebooks/Spell_checker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount drive"
      ],
      "metadata": {
        "id": "6kCQ2n5_NwZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1R5TlIRAN4_s",
        "outputId": "51b10165-b5df-4573-b729-edcd0781c002"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Spelling Errors:\n",
        "Focus on the correct arrangement of letters in a word to match its standard or dictionary form.\n",
        "- Example: \"adres\" instead of \"address.\"\n",
        "\n",
        "Grammar Errors:\n",
        "Focus on the syntax, word forms, and sentence structure to convey proper meaning and adhere to language rules.\n",
        "- Example: \"He going to school yesterday\" instead of \"He went to school yesterday.\""
      ],
      "metadata": {
        "id": "SB3evSA56p8p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Edit Distance (Levenshtein Distance)\n"
      ],
      "metadata": {
        "id": "prM_0v8XxJ-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Levenshtein library in Python is a specialized tool for computing Levenshtein distances\n",
        "\n",
        "- Levenshtein Distance: Calculates the minimum edit distance between two strings.\n",
        "- Levenshtein Similarity: Measures how similar two strings are, typically on a scale from 0 to 1.\n",
        "- Other Metrics:\n",
        " - Ratio: A normalized version of the distance (1 - distance/max length).\n",
        " - Hamming Distance: Number of positions where two strings of equal length differ.\n",
        " - Jaro-Winkler Similarity: A more nuanced similarity metric, especially for short strings."
      ],
      "metadata": {
        "id": "zoSzNjSn3-M6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6oPOMCsjQ8nN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0e00bad-29cc-4633-efec-3e2b07279eee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.26.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting Levenshtein==0.26.1 (from python-Levenshtein)\n",
            "  Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.26.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading python_Levenshtein-0.26.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.26.1 python-Levenshtein-0.26.1 rapidfuzz-3.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install python-Levenshtein"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Sinhala dictionary (dataset 01)"
      ],
      "metadata": {
        "id": "raDHIiZiH1t6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split word from sentence"
      ],
      "metadata": {
        "id": "oYFYcBq7yi9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the input text file in read mode\n",
        "with open('/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_full_word_list_2016-10-08.txt', 'r', encoding='utf-8') as infile:\n",
        "    # Read all lines from the input file\n",
        "    lines = infile.readlines()\n",
        "\n",
        "# Create a list to store all words\n",
        "words = []\n",
        "\n",
        "# Loop through each line to extract words\n",
        "for line in lines:\n",
        "    # Split the line into words and extend the list\n",
        "    words.extend(line.split())\n"
      ],
      "metadata": {
        "id": "Ew4UBia4wP47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove dublicate words"
      ],
      "metadata": {
        "id": "DQHZ_PdyyrXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_words = []\n",
        "seen = set()\n",
        "for word in words:\n",
        "    if word not in seen:\n",
        "        unique_words.append(word)\n",
        "        seen.add(word)"
      ],
      "metadata": {
        "id": "9pCQ9qkNy6ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove Non sinhala words"
      ],
      "metadata": {
        "id": "U9uroFdYzhjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Sinhala Unicode character range\n",
        "sinhala_pattern = re.compile(r'^[\\u0D80-\\u0DFF]+$')\n",
        "\n",
        "# Filter Sinhala words\n",
        "sinhala_words = [word for word in unique_words if sinhala_pattern.match(word)]"
      ],
      "metadata": {
        "id": "HXdt1cU61Nje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Open the output CSV file in write mode\n",
        "with open('/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict1.csv', 'w', encoding='utf-8', newline='') as outfile:\n",
        "    writer = csv.writer(outfile)\n",
        "\n",
        "    # Write each word as a new row in the CSV\n",
        "    for word in sinhala_words:\n",
        "        writer.writerow([word])\n",
        "\n",
        "print(\"Words have been written to 'sinhala_dict1.csv' line by line.\")\n"
      ],
      "metadata": {
        "id": "FaRoNcXmmpGM",
        "outputId": "0b60ad66-e69f-4dc0-aa46-04f44672c863",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words have been written to 'sinhala_dict1.csv' line by line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset 02"
      ],
      "metadata": {
        "id": "laK3SdEkhJI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the .xlsx file\n",
        "file_path = \"/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/data-spell-checker.xlsx\"  # Replace with your file's path\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Filter the rows where label == 1\n",
        "filtered_data = data[data['label'] == 1]\n",
        "\n",
        "# Select only the words column\n",
        "words_with_label_1 = filtered_data['word']\n",
        "\n",
        "# Save the filtered words to a .csv file\n",
        "output_file_path = \"/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict2.csv\"  # Replace with your desired output file name\n",
        "words_with_label_1.to_csv(output_file_path, index=False, header=False)\n",
        "\n",
        "print(f\"Filtered words saved to {output_file_path}\")\n"
      ],
      "metadata": {
        "id": "n3ERZwvPhNSt",
        "outputId": "5ddade8a-9259-473f-edc0-6e05b0160b22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered words saved to /content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spell check"
      ],
      "metadata": {
        "id": "TvNhSULFJfj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load the dictionary from a text file\n",
        "def load_dictionary(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        dictionary = [line.strip() for line in file]\n",
        "    return dictionary"
      ],
      "metadata": {
        "id": "Ckj-t101O9Gy"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import Levenshtein\n",
        "\n",
        "def spell_check(word, dictionary, top_n=3):\n",
        "    # List to store words with their distances\n",
        "    word_distances = []\n",
        "\n",
        "    for correct_word in dictionary:\n",
        "        # Calculate the Levenshtein distance between the word and dictionary word\n",
        "        distance = Levenshtein.distance(word, correct_word)\n",
        "        word_distances.append((correct_word, distance))\n",
        "\n",
        "    # Sort the list by distance (ascending order)\n",
        "    word_distances.sort(key=lambda x: x[1])\n",
        "\n",
        "    # Return the top N closest words\n",
        "    return word_distances[:top_n]\n",
        "\n",
        "def check_sentence(sentence, sinhala_dictionary):\n",
        "    words = sentence.split()  # Split the input sentence into words\n",
        "    corrected_words = []  # List to store corrected words\n",
        "    distances = []  # List to store Levenshtein distances for each word\n",
        "\n",
        "    for word in words:\n",
        "        # Get the top suggestion (closest word) and its distance\n",
        "        top_words = spell_check(word, sinhala_dictionary, top_n=3)\n",
        "        if top_words:  # Ensure there's at least one suggestion\n",
        "            corrected_word, distance = top_words[0]  # Top suggestion\n",
        "            corrected_words.append(corrected_word)  # Add corrected word\n",
        "            distances.append(distance)  # Add the distance\n",
        "        else:\n",
        "            # If no suggestions, append the original word\n",
        "            corrected_words.append(word)\n",
        "            distances.append(None)  # No distance available\n",
        "\n",
        "        print_suggestion(word, top_words)\n",
        "\n",
        "    # Combine corrected words into a single sentence\n",
        "    corrected_sentence = ' '.join(corrected_words)\n",
        "\n",
        "    # Return values\n",
        "    return sentence, corrected_sentence, distances\n",
        "\n",
        "def print_suggestion(word, top_words):\n",
        "    print(f\"Suggestions for '{word}':\")\n",
        "    for i, (correct_word, distance) in enumerate(top_words, 1):\n",
        "        print(f\"{i}. {correct_word} (Distance: {distance})\")"
      ],
      "metadata": {
        "id": "JR3rxjzBZ4Pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dictionary from the text file\n",
        "sinhala_dictionary = load_dictionary('/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict2.csv')\n",
        "\n",
        "# Input word\n",
        "sentence = \"මම පොත් ලයනවා\"\n",
        "\n",
        "# Perform spell check\n",
        "sentence, corrected_sentence, distances = check_sentence(sentence, sinhala_dictionary)\n",
        "print(f\"\\nInput Sentence: {sentence}\")\n",
        "print(f\"Suggested Correction: {corrected_sentence}\")\n",
        "print(f\"Levenshtein Distances: {distances}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ANPOpArwrW-",
        "outputId": "d198ca34-4a1c-4451-a854-5684e593b804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suggestions for 'මම':\n",
            "1. මම (Distance: 0)\n",
            "2. ඇම (Distance: 1)\n",
            "3. ඉම (Distance: 1)\n",
            "Suggestions for 'පොත්':\n",
            "1. පහත් (Distance: 1)\n",
            "2. පොතන (Distance: 1)\n",
            "3. පොත්ත (Distance: 1)\n",
            "Suggestions for 'ලයනවා':\n",
            "1. උයනවා (Distance: 1)\n",
            "2. ගයනවා (Distance: 1)\n",
            "3. යනවා (Distance: 1)\n",
            "\n",
            "Input Sentence: මම පොත් ලයනවා\n",
            "Suggested Correction: මම පහත් උයනවා\n",
            "Levenshtein Distances: [0, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# International Phonetic Alphabet to Sinhala"
      ],
      "metadata": {
        "id": "10CJBlcEO_ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sinhala_to_ipa(text):\n",
        "    consonant_map = {\n",
        "        \"ක\": \"k\", \"ඛ\": \"kʰ\", \"ග\": \"ɡ\", \"ඝ\": \"ɡʱ\",\n",
        "        \"ඞ\": \"ŋ\", \"ඟ\": \"ŋɡ\", \"ච\": \"ʧ\", \"ඡ\": \"ʧʰ\",\n",
        "        \"ජ\": \"ʤ\", \"ඣ\": \"ʤʱ\", \"ඤ\": \"ɲ\", \"ඥ\": \"ɡn\",\n",
        "        \"ට\": \"ʈ\", \"ඨ\": \"ʈʰ\", \"ඩ\": \"ɖ\", \"ඪ\": \"ɖʱ\",\n",
        "        \"ණ\": \"ɳ\", \"ත\": \"t̪\", \"ථ\": \"t̪ʰ\", \"ද\": \"d̪\",\n",
        "        \"ධ\": \"d̪ʱ\", \"න\": \"n̪\", \"ප\": \"p\", \"ඵ\": \"pʰ\",\n",
        "        \"බ\": \"b\", \"භ\": \"bʱ\", \"ම\": \"m\", \"ය\": \"j\",\n",
        "        \"ර\": \"r\", \"ල\": \"l\", \"ව\": \"ʋ\", \"ශ\": \"ʃ\",\n",
        "        \"ෂ\": \"ʂ\", \"ස\": \"s\", \"හ\": \"h\", \"ළ\": \"ɭ\",\n",
        "        \"ෆ\": \"f\"\n",
        "    }\n",
        "\n",
        "    vowel_map = {\n",
        "        \"අ\": \"ʌ\", \"ආ\": \"aː\", \"ඇ\": \"æ\", \"ඈ\": \"æː\",\n",
        "        \"ඉ\": \"i\", \"ඊ\": \"iː\", \"උ\": \"u\", \"ඌ\": \"uː\",\n",
        "        \"එ\": \"e\", \"ඒ\": \"eː\", \"ඔ\": \"o\", \"ඕ\": \"oː\",\n",
        "        \"ා\": \"aː\", \"ැ\": \"æ\", \"ෑ\": \"æː\", \"ි\": \"i\",\n",
        "        \"ී\": \"iː\", \"ු\": \"u\", \"ූ\": \"uː\", \"ෙ\": \"e\",\n",
        "        \"ේ\": \"eː\", \"ො\": \"o\", \"ෝ\": \"oː\", \"ෞ\": \"au\"\n",
        "    }\n",
        "\n",
        "    def get_next_chars(pos, text, count=3):\n",
        "        result = []\n",
        "        for i in range(count):\n",
        "            if pos + i < len(text):\n",
        "                result.append(text[pos + i])\n",
        "            else:\n",
        "                result.append(None)\n",
        "        return result\n",
        "\n",
        "    def process_syllable(pos, text):\n",
        "        char = text[pos]\n",
        "        next_chars = get_next_chars(pos + 1, text)\n",
        "\n",
        "        if char == \" \":\n",
        "            return \"| \", 1\n",
        "\n",
        "        if char == \"අ\" and next_chars[0] == \"ං\":\n",
        "            return \"ʌŋ \", 2\n",
        "\n",
        "        if char == \"ං\":\n",
        "            return \"\", 1\n",
        "\n",
        "        if char in consonant_map:\n",
        "            if char == \"න\" and pos + 2 < len(text) and text[pos:pos+3] == \"නවා\":\n",
        "                return \"n̪ ə \", 1\n",
        "\n",
        "            if char == \"ව\" and pos + 1 < len(text) and text[pos:pos+2] == \"වා\":\n",
        "                return \"ʋ a \", 2\n",
        "\n",
        "            base = consonant_map[char] + \" \"\n",
        "\n",
        "            if next_chars[0] in vowel_map:\n",
        "                return base, 1\n",
        "            elif next_chars[0] == \"්\":\n",
        "                return base, 2\n",
        "            elif pos == len(text) - 1:\n",
        "                return base + \"ə \", 1\n",
        "            else:\n",
        "                if char == \"ක\" and pos == 1:\n",
        "                    return base + \"ʌ \", 1\n",
        "                else:\n",
        "                    return base + \"ʌ \", 1\n",
        "\n",
        "        elif char in vowel_map:\n",
        "            if char == \"ා\" and pos == len(text) - 1:\n",
        "                return \"\", 1\n",
        "            return vowel_map[char] + \" \", 1\n",
        "\n",
        "        elif char == \"්\":\n",
        "            return \"\", 1\n",
        "\n",
        "        return char + \" \", 1\n",
        "\n",
        "    result = \"\"\n",
        "    i = 0\n",
        "    while i < len(text):\n",
        "        segment, skip = process_syllable(i, text)\n",
        "        result += segment\n",
        "        i += skip\n",
        "\n",
        "    result = result.strip()\n",
        "    while \"  \" in result:\n",
        "        result = result.replace(\"  \", \" \")\n",
        "\n",
        "    return result\n",
        "\n",
        "def ipa_to_sinhala(ipa_text):\n",
        "    ipa_map = {\n",
        "        # Base vowels\n",
        "        \"ʌ\": \"අ\", \"aː\": \"ආ\", \"æ\": \"ඇ\", \"æː\": \"ඈ\",\n",
        "        \"i\": \"ඉ\", \"iː\": \"ඊ\", \"u\": \"උ\", \"uː\": \"ඌ\",\n",
        "        \"e\": \"එ\", \"eː\": \"ඒ\", \"o\": \"ඔ\", \"oː\": \"ඕ\",\n",
        "\n",
        "        # Consonants\n",
        "        \"k\": \"ක\", \"kʰ\": \"ඛ\", \"ɡ\": \"ග\", \"ɡʱ\": \"ඝ\",\n",
        "        \"ŋ\": \"ං\", \"ŋɡ\": \"ඟ\", \"ʧ\": \"ච\", \"ʧʰ\": \"ඡ\",\n",
        "        \"ʤ\": \"ජ\", \"ʤʱ\": \"ඣ\", \"ɲ\": \"ඤ\", \"ʈ\": \"ට\",\n",
        "        \"ʈʰ\": \"ඨ\", \"ɖ\": \"ඩ\", \"ɖʱ\": \"ඪ\", \"ɳ\": \"ණ\",\n",
        "        \"t̪\": \"ත\", \"t̪ʰ\": \"ථ\", \"d̪\": \"ද\", \"d̪ʱ\": \"ධ\",\n",
        "        \"n̪\": \"න\", \"p\": \"ප\", \"pʰ\": \"ඵ\", \"b\": \"බ\",\n",
        "        \"bʱ\": \"භ\", \"m\": \"ම\", \"j\": \"ය\", \"r\": \"ර\",\n",
        "        \"l\": \"ල\", \"ʋ\": \"ව\", \"s\": \"ස\", \"h\": \"හ\",\n",
        "        \"ʃ\": \"ශ\", \"ʂ\": \"ෂ\", \"ɭ\": \"ළ\", \"f\": \"ෆ\"\n",
        "    }\n",
        "\n",
        "    # Split IPA text into words using the vertical bar or multiple spaces as delimiter\n",
        "    words = [word.strip() for word in ipa_text.replace(\"|\", \" \").split(\"  \")]\n",
        "    result = []\n",
        "\n",
        "    for word in words:\n",
        "        tokens = word.split()\n",
        "        word_result = \"\"\n",
        "        i = 0\n",
        "\n",
        "        while i < len(tokens):\n",
        "            token = tokens[i]\n",
        "            remaining_tokens = tokens[i:]\n",
        "\n",
        "            if token == \"ʌŋ\" or (token == \"ʌ\" and i + 1 < len(tokens) and tokens[i+1] == \"ŋ\"):\n",
        "                word_result += \"අං\"\n",
        "                i += 2 if token == \"ʌ\" else 1\n",
        "                continue\n",
        "\n",
        "            if len(remaining_tokens) >= 4 and remaining_tokens[0:4] == [\"n̪\", \"ə\", \"ʋ\", \"a\"]:\n",
        "                word_result += \"නවා\"\n",
        "                i += 4\n",
        "                continue\n",
        "\n",
        "            if token in ipa_map:\n",
        "                word_result += ipa_map[token]\n",
        "\n",
        "                next_token = tokens[i + 1] if i + 1 < len(tokens) else None\n",
        "\n",
        "                if next_token == \"ə\":\n",
        "                    if i + 2 < len(tokens) and tokens[i+2] != \"j\":\n",
        "                        word_result += \"්\"\n",
        "                    i += 2\n",
        "                elif next_token == \"ʌ\":\n",
        "                    i += 2\n",
        "                elif next_token == \"a\":\n",
        "                    if i + 1 == len(tokens) - 1:\n",
        "                        word_result += \"ා\"\n",
        "                    i += 2\n",
        "                else:\n",
        "                    if token not in \"ʌaːæiːuːeːoː\":\n",
        "                        next_is_consonant = (next_token in ipa_map and\n",
        "                                          next_token not in \"ʌaːæiːuːeːoː\")\n",
        "                        if next_is_consonant and next_token != \"j\":\n",
        "                            word_result += \"්\"\n",
        "                    i += 1\n",
        "            else:\n",
        "                i += 1\n",
        "\n",
        "        result.append(word_result)\n",
        "\n",
        "    return \" \".join(result)\n",
        "\n",
        "# Test cases\n",
        "test_cases = [\n",
        "    (\"අංකනය\", \"ʌŋ k ʌ n̪ ə j ə\"),\n",
        "    (\"කරනවා\", \"k ʌ r ʌ n̪ ə ʋ a\"),\n",
        "    (\"ගහනවා\", \"ɡ ʌ h ʌ n̪ ə ʋ a\"),\n",
        "    (\"මට\", \"m ʌ ʈ ə\"),\n",
        "    (\"බලන්න\", \"b ʌ l ʌ n̪ n̪ ə\"),\n",
        "    (\"බලන්න අහස\", \"b ʌ l ʌ n̪ n̪ ʌ | ʌ h ʌ s ə\")\n",
        "]\n",
        "\n",
        "print(\"Testing Sinhala to IPA conversion:\")\n",
        "for sinhala, expected_ipa in test_cases:\n",
        "    result = sinhala_to_ipa(sinhala)\n",
        "    print(f\"Sinhala: {sinhala}\")\n",
        "    print(f\"Expected IPA: {expected_ipa}\")\n",
        "    print(f\"Got IPA: {result}\")\n",
        "    print()\n",
        "\n",
        "print(\"Testing IPA to Sinhala conversion:\")\n",
        "for sinhala, ipa in test_cases:\n",
        "    result = ipa_to_sinhala(ipa)\n",
        "    print(f\"IPA: {ipa}\")\n",
        "    print(f\"Expected Sinhala: {sinhala}\")\n",
        "    print(f\"Got Sinhala: {result}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "S5x7whNyv82N",
        "outputId": "e7725b90-dd02-4f80-d697-28f89dd21530",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Sinhala to IPA conversion:\n",
            "Sinhala: අංකනය\n",
            "Expected IPA: ʌŋ k ʌ n̪ ə j ə\n",
            "Got IPA: ʌŋ k ʌ n̪ ʌ j ə\n",
            "\n",
            "Sinhala: කරනවා\n",
            "Expected IPA: k ʌ r ʌ n̪ ə ʋ a\n",
            "Got IPA: k ʌ r ʌ n̪ ə ʋ a\n",
            "\n",
            "Sinhala: ගහනවා\n",
            "Expected IPA: ɡ ʌ h ʌ n̪ ə ʋ a\n",
            "Got IPA: ɡ ʌ h ʌ n̪ ə ʋ a\n",
            "\n",
            "Sinhala: මට\n",
            "Expected IPA: m ʌ ʈ ə\n",
            "Got IPA: m ʌ ʈ ə\n",
            "\n",
            "Sinhala: බලන්න\n",
            "Expected IPA: b ʌ l ʌ n̪ n̪ ə\n",
            "Got IPA: b ʌ l ʌ n̪ n̪ ə\n",
            "\n",
            "Sinhala: බලන්න අහස\n",
            "Expected IPA: b ʌ l ʌ n̪ n̪ ʌ | ʌ h ʌ s ə\n",
            "Got IPA: b ʌ l ʌ n̪ n̪ ʌ | ʌ h ʌ s ə\n",
            "\n",
            "Testing IPA to Sinhala conversion:\n",
            "IPA: ʌŋ k ʌ n̪ ə j ə\n",
            "Expected Sinhala: අංකනය\n",
            "Got Sinhala: අංකනය\n",
            "\n",
            "IPA: k ʌ r ʌ n̪ ə ʋ a\n",
            "Expected Sinhala: කරනවා\n",
            "Got Sinhala: කරනවා\n",
            "\n",
            "IPA: ɡ ʌ h ʌ n̪ ə ʋ a\n",
            "Expected Sinhala: ගහනවා\n",
            "Got Sinhala: ගහනවා\n",
            "\n",
            "IPA: m ʌ ʈ ə\n",
            "Expected Sinhala: මට\n",
            "Got Sinhala: මට\n",
            "\n",
            "IPA: b ʌ l ʌ n̪ n̪ ə\n",
            "Expected Sinhala: බලන්න\n",
            "Got Sinhala: බලන්න\n",
            "\n",
            "IPA: b ʌ l ʌ n̪ n̪ ʌ | ʌ h ʌ s ə\n",
            "Expected Sinhala: බලන්න අහස\n",
            "Got Sinhala: බලන්න අහස\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "sinhala_word = \"බලන්න අහස\"  # Input Sinhala word\n",
        "ipa_transcription = sinhala_to_ipa(sinhala_word)\n",
        "print(\"Sinhala Word:\", sinhala_word)\n",
        "print(\"IPA Transcription:\", ipa_transcription)"
      ],
      "metadata": {
        "id": "brn84GoSPIn5",
        "outputId": "bde0f743-318f-4f40-e635-428fb1c5b650",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sinhala Word: බලන්න අහස\n",
            "IPA Transcription: b ʌ l ʌ n̪ n̪ ʌ | ʌ h ʌ s ə\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset without headers (it doesn't have column names)\n",
        "file_path = '/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict2.csv'\n",
        "df = pd.read_csv(file_path, header=None, names=['word'])\n",
        "\n",
        "# Apply the `sinhala_to_ipa` function to each word\n",
        "df['IPA'] = df['word'].apply(sinhala_to_ipa)\n",
        "\n",
        "# Save the new dataset with 'word' and 'IPA' columns to a new CSV file\n",
        "output_path = '/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict_with_ipa.csv'\n",
        "df[['word', 'IPA']].to_csv(output_path, index=False)\n",
        "\n",
        "print(\"New dataset with IPA has been saved to:\", output_path)\n"
      ],
      "metadata": {
        "id": "It8aB3VyaviM",
        "outputId": "778dd357-0189-464f-fa46-d5ca4fd7cba7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New dataset with IPA has been saved to: /content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict_with_ipa.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "nvkfBGildDy7",
        "outputId": "d6054f8b-f458-422d-9f8a-f622ed0a6267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            word                      IPA\n",
              "0      අභිචෝදකයා   ʌ bʱ i ʧ oː d̪ ʌ k ʌ j\n",
              "1          අංකනය          ʌŋ k ʌ n̪ ʌ j ə\n",
              "2           අංකන              ʌŋ k ʌ n̪ ə\n",
              "3           අංකය               ʌŋ k ʌ j ə\n",
              "4      අංකාන්තරය  ʌŋ k aː n̪ t̪ ʌ r ʌ j ə\n",
              "...          ...                      ...\n",
              "67255      හැරීය             h æ r iː j ə\n",
              "67256  හැරීයන්නේ    h æ r iː j ʌ n̪ n̪ eː\n",
              "67257    හැරීයයි         h æ r iː j ʌ j i\n",
              "67258    හැරීයාම        h æ r iː j aː m ə\n",
              "67259   හැරීයොත්          h æ r iː j o t̪\n",
              "\n",
              "[67260 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90acab9c-d08e-48e8-8045-01c595490c2e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>IPA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>අභිචෝදකයා</td>\n",
              "      <td>ʌ bʱ i ʧ oː d̪ ʌ k ʌ j</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>අංකනය</td>\n",
              "      <td>ʌŋ k ʌ n̪ ʌ j ə</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>අංකන</td>\n",
              "      <td>ʌŋ k ʌ n̪ ə</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>අංකය</td>\n",
              "      <td>ʌŋ k ʌ j ə</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>අංකාන්තරය</td>\n",
              "      <td>ʌŋ k aː n̪ t̪ ʌ r ʌ j ə</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67255</th>\n",
              "      <td>හැරීය</td>\n",
              "      <td>h æ r iː j ə</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67256</th>\n",
              "      <td>හැරීයන්නේ</td>\n",
              "      <td>h æ r iː j ʌ n̪ n̪ eː</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67257</th>\n",
              "      <td>හැරීයයි</td>\n",
              "      <td>h æ r iː j ʌ j i</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67258</th>\n",
              "      <td>හැරීයාම</td>\n",
              "      <td>h æ r iː j aː m ə</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67259</th>\n",
              "      <td>හැරීයොත්</td>\n",
              "      <td>h æ r iː j o t̪</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>67260 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90acab9c-d08e-48e8-8045-01c595490c2e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-90acab9c-d08e-48e8-8045-01c595490c2e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-90acab9c-d08e-48e8-8045-01c595490c2e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7a49a8b1-9833-45fa-b2a4-2f41cc03a180\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7a49a8b1-9833-45fa-b2a4-2f41cc03a180')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7a49a8b1-9833-45fa-b2a4-2f41cc03a180 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_460723bf-9166-4f75-9da8-4bf49865120b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_460723bf-9166-4f75-9da8-4bf49865120b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 67260,\n  \"fields\": [\n    {\n      \"column\": \"word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 67260,\n        \"samples\": [\n          \"\\u0dc3\\u0dd2\\u0dad\\u0d9a\\u0dca\",\n          \"\\u0dc3\\u0dca\\u0db4\\u0dca\\u200d\\u0dba\\u0daf\\u0dca\",\n          \"\\u0dc3\\u0dd8\\u0da2\\u0dd4\\u0dc0\\u0dd3\\u0db8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IPA\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 66898,\n        \"samples\": [\n          \"b \\u028c l \\u028c h \\u028c t\\u032a k a\\u02d0 r \\u0259\",\n          \"h \\u028c j i h \\u028c j i j e n\\u032a\",\n          \"\\u028b i s m i t\\u032a \\u028c \\u028b \\u0259\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import Levenshtein\n",
        "\n",
        "def spell_check(word, dictionary, top_n=3):\n",
        "    # List to store words with their distances\n",
        "    word_distances = []\n",
        "\n",
        "    for correct_word in dictionary:\n",
        "        # Calculate the Levenshtein distance between the word and dictionary word\n",
        "        distance = Levenshtein.distance(word, correct_word)\n",
        "        word_distances.append((correct_word, distance))\n",
        "\n",
        "    # Sort the list by distance (ascending order)\n",
        "    word_distances.sort(key=lambda x: x[1])\n",
        "\n",
        "    # Return the top N closest words\n",
        "    return word_distances[:top_n]\n",
        "\n",
        "def check_sentence(sentence, sinhala_dictionary):\n",
        "    words = sentence.split()  # Split the input sentence into words\n",
        "    corrected_words = []  # List to store corrected words\n",
        "    distances = []  # List to store Levenshtein distances for each word\n",
        "\n",
        "    for word in words:\n",
        "        # Get the top suggestion (closest word) and its distance\n",
        "        top_words = spell_check(word, sinhala_dictionary, top_n=3)\n",
        "        if top_words:  # Ensure there's at least one suggestion\n",
        "            corrected_word, distance = top_words[0]  # Top suggestion\n",
        "            corrected_words.append(corrected_word)  # Add corrected word\n",
        "            distances.append(distance)  # Add the distance\n",
        "        else:\n",
        "            # If no suggestions, append the original word\n",
        "            corrected_words.append(word)\n",
        "            distances.append(None)  # No distance available\n",
        "\n",
        "        print_suggestion(word, top_words)\n",
        "\n",
        "    # Combine corrected words into a single sentence\n",
        "    corrected_sentence = ' '.join(corrected_words)\n",
        "\n",
        "    # Return values\n",
        "    return sentence, corrected_sentence, distances\n",
        "\n",
        "def print_suggestion(word, top_words):\n",
        "    print(f\"Suggestions for '{word}':\")\n",
        "    for i, (correct_word, distance) in enumerate(top_words, 1):\n",
        "        print(f\"{i}. {correct_word} (Distance: {distance})\")"
      ],
      "metadata": {
        "id": "3VTa8FZ9bpre"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import Levenshtein\n",
        "\n",
        "def spell_check(word, dictionary, top_n=3):\n",
        "    # List to store words with their distances\n",
        "    word_distances = []\n",
        "\n",
        "    for correct_word in dictionary:\n",
        "        # Calculate the Levenshtein distance between the word and dictionary word\n",
        "        distance = Levenshtein.distance(word, correct_word)\n",
        "        word_distances.append((correct_word, distance))\n",
        "\n",
        "    # Sort the list by distance (ascending order)\n",
        "    word_distances.sort(key=lambda x: x[1])\n",
        "\n",
        "    # Return the top N closest words\n",
        "    return word_distances[:top_n]\n",
        "\n",
        "def check_sentence(sentence, sinhala_dictionary):\n",
        "    words = sentence.split()  # Split the input sentence into words\n",
        "    corrected_words = []  # List to store corrected words\n",
        "    distances = []  # List to store Levenshtein distances for each word\n",
        "\n",
        "    for word in words:\n",
        "        # Get the top suggestion (closest word) and its distance\n",
        "        top_words = spell_check(sinhala_to_ipa(word), sinhala_dictionary, top_n=3)\n",
        "        if top_words:  # Ensure there's at least one suggestion\n",
        "            corrected_word, distance = top_words[0]  # Top suggestion\n",
        "            corrected_words.append(ipa_to_sinhala(corrected_word))  # Add corrected word\n",
        "            distances.append(distance)  # Add the distance\n",
        "        else:\n",
        "            # If no suggestions, append the original word\n",
        "            corrected_words.append(word)\n",
        "            distances.append(None)  # No distance available\n",
        "\n",
        "        print_suggestion(word, top_words)\n",
        "\n",
        "    # Combine corrected words into a single sentence\n",
        "    corrected_sentence = ' '.join(corrected_words)\n",
        "\n",
        "    # Return values\n",
        "    return sentence, corrected_sentence, distances\n",
        "\n",
        "def print_suggestion(word, top_words):\n",
        "    top_words = [(ipa_to_sinhala(correct_word), distance) for correct_word, distance in top_words]\n",
        "    print(f\"Suggestions for '{word}':\")\n",
        "    for i, (correct_word, distance) in enumerate(top_words, 1):\n",
        "        print(f\"{i}. {correct_word} (Distance: {distance})\")"
      ],
      "metadata": {
        "id": "PU2YKCXoyzsO"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def load_dictionary(file_path):\n",
        "  df = pd.read_csv(file_path)\n",
        "  return df"
      ],
      "metadata": {
        "id": "d1YGFAI1uUnH"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dictionary from the text file\n",
        "sinhala_dictionary = load_dictionary('/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict_with_ipa.csv')\n",
        "\n",
        "# Input word\n",
        "sentence = \"මම ආහස බලනව\"\n",
        "\n",
        "# Perform spell check\n",
        "sentence, corrected_sentence, distances = check_sentence(sentence, sinhala_dictionary['IPA'])\n",
        "print(f\"\\nInput Sentence: {sentence}\")\n",
        "print(f\"Suggested Correction: {corrected_sentence}\")\n",
        "print(f\"Levenshtein Distances: {distances}\")"
      ],
      "metadata": {
        "id": "xO_E-2-JeWKR",
        "outputId": "19d248ab-e601-4fe4-911f-3ef4bbd5f36b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suggestions for 'මම':\n",
            "1. මම (Distance: 0)\n",
            "2. ගම (Distance: 1)\n",
            "3. මඩ (Distance: 1)\n",
            "Suggestions for 'ආහස':\n",
            "1. අහස (Distance: 2)\n",
            "2. ආගම (Distance: 2)\n",
            "3. ආපසඋ (Distance: 2)\n",
            "Suggestions for 'බලනව':\n",
            "1. කලනය (Distance: 2)\n",
            "2. බමනය (Distance: 2)\n",
            "3. බලතල (Distance: 2)\n",
            "\n",
            "Input Sentence: මම ආහස බලනව\n",
            "Suggested Correction: මම අහස කලනය\n",
            "Levenshtein Distances: [0, 2, 2]\n"
          ]
        }
      ]
    }
  ]
}