{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFreXHHuA6c9TkSoOn2SQQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nuwantha97/Sinhala_spell_and_grammer_checker/blob/Notebooks/Spell_checker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount drive"
      ],
      "metadata": {
        "id": "6kCQ2n5_NwZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1R5TlIRAN4_s",
        "outputId": "fa0e2d9d-b815-41fd-a505-3c51689b8b01"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Spelling Errors:\n",
        "Focus on the correct arrangement of letters in a word to match its standard or dictionary form.\n",
        "- Example: \"adres\" instead of \"address.\"\n",
        "\n",
        "Grammar Errors:\n",
        "Focus on the syntax, word forms, and sentence structure to convey proper meaning and adhere to language rules.\n",
        "- Example: \"He going to school yesterday\" instead of \"He went to school yesterday.\""
      ],
      "metadata": {
        "id": "SB3evSA56p8p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Edit Distance (Levenshtein Distance)\n"
      ],
      "metadata": {
        "id": "prM_0v8XxJ-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Levenshtein library in Python is a specialized tool for computing Levenshtein distances\n",
        "\n",
        "- Levenshtein Distance: Calculates the minimum edit distance between two strings.\n",
        "- Levenshtein Similarity: Measures how similar two strings are, typically on a scale from 0 to 1.\n",
        "- Other Metrics:\n",
        " - Ratio: A normalized version of the distance (1 - distance/max length).\n",
        " - Hamming Distance: Number of positions where two strings of equal length differ.\n",
        " - Jaro-Winkler Similarity: A more nuanced similarity metric, especially for short strings."
      ],
      "metadata": {
        "id": "zoSzNjSn3-M6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6oPOMCsjQ8nN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "261a9d68-d112-4623-9cbd-34f53ed7d6d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.26.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting Levenshtein==0.26.1 (from python-Levenshtein)\n",
            "  Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.26.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading python_Levenshtein-0.26.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.26.1 python-Levenshtein-0.26.1 rapidfuzz-3.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install python-Levenshtein"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Sinhala dictionary (dataset 01)"
      ],
      "metadata": {
        "id": "raDHIiZiH1t6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split word from sentence"
      ],
      "metadata": {
        "id": "oYFYcBq7yi9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the input text file in read mode\n",
        "with open('/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_full_word_list_2016-10-08.txt', 'r', encoding='utf-8') as infile:\n",
        "    # Read all lines from the input file\n",
        "    lines = infile.readlines()\n",
        "\n",
        "# Create a list to store all words\n",
        "words = []\n",
        "\n",
        "# Loop through each line to extract words\n",
        "for line in lines:\n",
        "    # Split the line into words and extend the list\n",
        "    words.extend(line.split())\n"
      ],
      "metadata": {
        "id": "Ew4UBia4wP47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove dublicate words"
      ],
      "metadata": {
        "id": "DQHZ_PdyyrXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_words = []\n",
        "seen = set()\n",
        "for word in words:\n",
        "    if word not in seen:\n",
        "        unique_words.append(word)\n",
        "        seen.add(word)"
      ],
      "metadata": {
        "id": "9pCQ9qkNy6ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove Non sinhala words"
      ],
      "metadata": {
        "id": "U9uroFdYzhjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Sinhala Unicode character range\n",
        "sinhala_pattern = re.compile(r'^[\\u0D80-\\u0DFF]+$')\n",
        "\n",
        "# Filter Sinhala words\n",
        "sinhala_words = [word for word in unique_words if sinhala_pattern.match(word)]"
      ],
      "metadata": {
        "id": "HXdt1cU61Nje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Open the output CSV file in write mode\n",
        "with open('/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict1.csv', 'w', encoding='utf-8', newline='') as outfile:\n",
        "    writer = csv.writer(outfile)\n",
        "\n",
        "    # Write each word as a new row in the CSV\n",
        "    for word in sinhala_words:\n",
        "        writer.writerow([word])\n",
        "\n",
        "print(\"Words have been written to 'sinhala_dict1.csv' line by line.\")\n"
      ],
      "metadata": {
        "id": "FaRoNcXmmpGM",
        "outputId": "0b60ad66-e69f-4dc0-aa46-04f44672c863",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words have been written to 'sinhala_dict1.csv' line by line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset 02"
      ],
      "metadata": {
        "id": "laK3SdEkhJI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the .xlsx file\n",
        "file_path = \"/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/data-spell-checker.xlsx\"  # Replace with your file's path\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Filter the rows where label == 1\n",
        "filtered_data = data[data['label'] == 1]\n",
        "\n",
        "# Select only the words column\n",
        "words_with_label_1 = filtered_data['word']\n",
        "\n",
        "# Save the filtered words to a .csv file\n",
        "output_file_path = \"/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict2.csv\"  # Replace with your desired output file name\n",
        "words_with_label_1.to_csv(output_file_path, index=False, header=False)\n",
        "\n",
        "print(f\"Filtered words saved to {output_file_path}\")\n"
      ],
      "metadata": {
        "id": "n3ERZwvPhNSt",
        "outputId": "0d11654d-834e-4346-8250-142f82f9d51d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered words saved to /content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# International Phonetic Alphabet to Sinhala"
      ],
      "metadata": {
        "id": "10CJBlcEO_ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sinhala_to_ipa(text):\n",
        "    consonant_map = {\n",
        "        \"ක\": \"k\", \"ඛ\": \"kʰ\", \"ග\": \"ɡ\", \"ඝ\": \"ɡʱ\",\n",
        "        \"ඞ\": \"ŋ\", \"ඟ\": \"ŋɡ\", \"ච\": \"ʧ\", \"ඡ\": \"ʧʰ\",\n",
        "        \"ජ\": \"ʤ\", \"ඣ\": \"ʤʱ\", \"ඤ\": \"ɲ\", \"ඥ\": \"ɡn\",\n",
        "        \"ට\": \"ʈ\", \"ඨ\": \"ʈʰ\", \"ඩ\": \"ɖ\", \"ඪ\": \"ɖʱ\",\n",
        "        \"ණ\": \"ɳ\", \"ත\": \"t̪\", \"ථ\": \"t̪ʰ\", \"ද\": \"d̪\",\n",
        "        \"ධ\": \"d̪ʱ\", \"න\": \"n̪\", \"ප\": \"p\", \"ඵ\": \"pʰ\",\n",
        "        \"බ\": \"b\", \"භ\": \"bʱ\", \"ම\": \"m\", \"ය\": \"j\",\n",
        "        \"ර\": \"r\", \"ල\": \"l\", \"ව\": \"ʋ\", \"ශ\": \"ʃ\",\n",
        "        \"ෂ\": \"ʂ\", \"ස\": \"s\", \"හ\": \"h\", \"ළ\": \"ɭ\",\n",
        "        \"ෆ\": \"f\"\n",
        "    }\n",
        "\n",
        "    vowel_map = {\n",
        "        \"අ\": \"ʌ\", \"ආ\": \"aː\", \"ඇ\": \"æ\", \"ඈ\": \"æː\",\n",
        "        \"ඉ\": \"i\", \"ඊ\": \"iː\", \"උ\": \"u\", \"ඌ\": \"uː\",\n",
        "        \"එ\": \"e\", \"ඒ\": \"eː\", \"ඔ\": \"o\", \"ඕ\": \"oː\",\n",
        "        \"ා\": \"aː\", \"ැ\": \"æ\", \"ෑ\": \"æː\", \"ි\": \"i\",\n",
        "        \"ී\": \"iː\", \"ු\": \"u\", \"ූ\": \"uː\", \"ෙ\": \"e\",\n",
        "        \"ේ\": \"eː\", \"ො\": \"o\", \"ෝ\": \"oː\", \"ෞ\": \"au\"\n",
        "    }\n",
        "\n",
        "    def get_next_chars(pos, text, count=3):\n",
        "        result = []\n",
        "        for i in range(count):\n",
        "            if pos + i < len(text):\n",
        "                result.append(text[pos + i])\n",
        "            else:\n",
        "                result.append(None)\n",
        "        return result\n",
        "\n",
        "    def process_syllable(pos, text):\n",
        "        char = text[pos]\n",
        "        next_chars = get_next_chars(pos + 1, text)\n",
        "\n",
        "        if char == \" \":\n",
        "            return \"| \", 1\n",
        "\n",
        "        if char == \"අ\" and next_chars[0] == \"ං\":\n",
        "            return \"ʌŋ \", 2\n",
        "\n",
        "        if char == \"ං\":\n",
        "            return \"\", 1\n",
        "\n",
        "        if char in consonant_map:\n",
        "            if char == \"න\" and pos + 2 < len(text) and text[pos:pos+3] == \"නවා\":\n",
        "                return \"n̪ ə \", 1\n",
        "\n",
        "            if char == \"ව\" and pos + 1 < len(text) and text[pos:pos+2] == \"වා\":\n",
        "                return \"ʋ a \", 2\n",
        "\n",
        "            base = consonant_map[char] + \" \"\n",
        "\n",
        "            if next_chars[0] in vowel_map:\n",
        "                return base, 1\n",
        "            elif next_chars[0] == \"්\":\n",
        "                return base, 2\n",
        "            elif pos == len(text) - 1:\n",
        "                return base + \"ə \", 1\n",
        "            else:\n",
        "                if char == \"ක\" and pos == 1:\n",
        "                    return base + \"ʌ \", 1\n",
        "                else:\n",
        "                    return base + \"ʌ \", 1\n",
        "\n",
        "        elif char in vowel_map:\n",
        "            if char == \"ා\" and pos == len(text) - 1:\n",
        "                return \"\", 1\n",
        "            return vowel_map[char] + \" \", 1\n",
        "\n",
        "        elif char == \"්\":\n",
        "            return \"\", 1\n",
        "\n",
        "        return char + \" \", 1\n",
        "\n",
        "    result = \"\"\n",
        "    i = 0\n",
        "    while i < len(text):\n",
        "        segment, skip = process_syllable(i, text)\n",
        "        result += segment\n",
        "        i += skip\n",
        "\n",
        "    result = result.strip()\n",
        "    while \"  \" in result:\n",
        "        result = result.replace(\"  \", \" \")\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "S5x7whNyv82N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ipa_to_sinhala(ipa_text):\n",
        "    ipa_map = {\n",
        "        # Base vowels\n",
        "        \"ʌ\": \"අ\", \"aː\": \"ආ\", \"æ\": \"ඇ\", \"æː\": \"ඈ\",\n",
        "        \"i\": \"ඉ\", \"iː\": \"ඊ\", \"u\": \"උ\", \"uː\": \"ඌ\",\n",
        "        \"e\": \"එ\", \"eː\": \"ඒ\", \"o\": \"ඔ\", \"oː\": \"ඕ\",\n",
        "\n",
        "        # Consonants\n",
        "        \"k\": \"ක\", \"kʰ\": \"ඛ\", \"ɡ\": \"ග\", \"ɡʱ\": \"ඝ\",\n",
        "        \"ŋ\": \"ං\", \"ŋɡ\": \"ඟ\", \"ʧ\": \"ච\", \"ʧʰ\": \"ඡ\",\n",
        "        \"ʤ\": \"ජ\", \"ʤʱ\": \"ඣ\", \"ɲ\": \"ඤ\", \"ʈ\": \"ට\",\n",
        "        \"ʈʰ\": \"ඨ\", \"ɖ\": \"ඩ\", \"ɖʱ\": \"ඪ\", \"ɳ\": \"ණ\",\n",
        "        \"t̪\": \"ත\", \"t̪ʰ\": \"ථ\", \"d̪\": \"ද\", \"d̪ʱ\": \"ධ\",\n",
        "        \"n̪\": \"න\", \"p\": \"ප\", \"pʰ\": \"ඵ\", \"b\": \"බ\",\n",
        "        \"bʱ\": \"භ\", \"m\": \"ම\", \"j\": \"ය\", \"r\": \"ර\",\n",
        "        \"l\": \"ල\", \"ʋ\": \"ව\", \"s\": \"ස\", \"h\": \"හ\",\n",
        "        \"ʃ\": \"ශ\", \"ʂ\": \"ෂ\", \"ɭ\": \"ළ\", \"f\": \"ෆ\"\n",
        "    }\n",
        "\n",
        "    # Split IPA text into words using the vertical bar or multiple spaces as delimiter\n",
        "    words = [word.strip() for word in ipa_text.replace(\"|\", \" \").split(\"  \")]\n",
        "    result = []\n",
        "\n",
        "    for word in words:\n",
        "        tokens = word.split()\n",
        "        word_result = \"\"\n",
        "        i = 0\n",
        "\n",
        "        while i < len(tokens):\n",
        "            token = tokens[i]\n",
        "            remaining_tokens = tokens[i:]\n",
        "\n",
        "            if token == \"ʌŋ\" or (token == \"ʌ\" and i + 1 < len(tokens) and tokens[i+1] == \"ŋ\"):\n",
        "                word_result += \"අං\"\n",
        "                i += 2 if token == \"ʌ\" else 1\n",
        "                continue\n",
        "\n",
        "            if len(remaining_tokens) >= 4 and remaining_tokens[0:4] == [\"n̪\", \"ə\", \"ʋ\", \"a\"]:\n",
        "                word_result += \"නවා\"\n",
        "                i += 4\n",
        "                continue\n",
        "\n",
        "            if token in ipa_map:\n",
        "                word_result += ipa_map[token]\n",
        "\n",
        "                next_token = tokens[i + 1] if i + 1 < len(tokens) else None\n",
        "\n",
        "                if next_token == \"ə\":\n",
        "                    if i + 2 < len(tokens) and tokens[i+2] != \"j\":\n",
        "                        word_result += \"්\"\n",
        "                    i += 2\n",
        "                elif next_token == \"ʌ\":\n",
        "                    i += 2\n",
        "                elif next_token == \"a\":\n",
        "                    if i + 1 == len(tokens) - 1:\n",
        "                        word_result += \"ා\"\n",
        "                    i += 2\n",
        "                else:\n",
        "                    if token not in \"ʌaːæiːuːeːoː\":\n",
        "                        next_is_consonant = (next_token in ipa_map and\n",
        "                                          next_token not in \"ʌaːæiːuːeːoː\")\n",
        "                        if next_is_consonant and next_token != \"j\":\n",
        "                            word_result += \"්\"\n",
        "                    i += 1\n",
        "            else:\n",
        "                i += 1\n",
        "\n",
        "        result.append(word_result)\n",
        "\n",
        "    return \" \".join(result)"
      ],
      "metadata": {
        "id": "ZP2Ppx9criu2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test cases\n",
        "test_cases = [\n",
        "    (\"අංකනය\", \"ʌŋ k ʌ n̪ ə j ə\"),\n",
        "    (\"කරනවා\", \"k ʌ r ʌ n̪ ə ʋ a\"),\n",
        "    (\"ගහනවා\", \"ɡ ʌ h ʌ n̪ ə ʋ a\"),\n",
        "    (\"මට\", \"m ʌ ʈ ə\"),\n",
        "    (\"බලන්න\", \"b ʌ l ʌ n̪ n̪ ə\"),\n",
        "    (\"බලන්න අහස\", \"b ʌ l ʌ n̪ n̪ ʌ | ʌ h ʌ s ə\")\n",
        "]\n",
        "\n",
        "print(\"Testing Sinhala to IPA conversion:\")\n",
        "for sinhala, expected_ipa in test_cases:\n",
        "    result = sinhala_to_ipa(sinhala)\n",
        "    print(f\"Sinhala: {sinhala}\")\n",
        "    print(f\"Expected IPA: {expected_ipa}\")\n",
        "    print(f\"Got IPA: {result}\")\n",
        "    print()\n",
        "\n",
        "print(\"Testing IPA to Sinhala conversion:\")\n",
        "for sinhala, ipa in test_cases:\n",
        "    result = ipa_to_sinhala(ipa)\n",
        "    print(f\"IPA: {ipa}\")\n",
        "    print(f\"Expected Sinhala: {sinhala}\")\n",
        "    print(f\"Got Sinhala: {result}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "3B1fo5UZrosU",
        "outputId": "b4fe87e0-0132-47b2-b1e6-4d31ed6e007d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Sinhala to IPA conversion:\n",
            "Sinhala: අංකනය\n",
            "Expected IPA: ʌŋ k ʌ n̪ ə j ə\n",
            "Got IPA: ʌŋ k ʌ n̪ ʌ j ə\n",
            "\n",
            "Sinhala: කරනවා\n",
            "Expected IPA: k ʌ r ʌ n̪ ə ʋ a\n",
            "Got IPA: k ʌ r ʌ n̪ ə ʋ a\n",
            "\n",
            "Sinhala: ගහනවා\n",
            "Expected IPA: ɡ ʌ h ʌ n̪ ə ʋ a\n",
            "Got IPA: ɡ ʌ h ʌ n̪ ə ʋ a\n",
            "\n",
            "Sinhala: මට\n",
            "Expected IPA: m ʌ ʈ ə\n",
            "Got IPA: m ʌ ʈ ə\n",
            "\n",
            "Sinhala: බලන්න\n",
            "Expected IPA: b ʌ l ʌ n̪ n̪ ə\n",
            "Got IPA: b ʌ l ʌ n̪ n̪ ə\n",
            "\n",
            "Sinhala: බලන්න අහස\n",
            "Expected IPA: b ʌ l ʌ n̪ n̪ ʌ | ʌ h ʌ s ə\n",
            "Got IPA: b ʌ l ʌ n̪ n̪ ʌ | ʌ h ʌ s ə\n",
            "\n",
            "Testing IPA to Sinhala conversion:\n",
            "IPA: ʌŋ k ʌ n̪ ə j ə\n",
            "Expected Sinhala: අංකනය\n",
            "Got Sinhala: අංකනය\n",
            "\n",
            "IPA: k ʌ r ʌ n̪ ə ʋ a\n",
            "Expected Sinhala: කරනවා\n",
            "Got Sinhala: කරනවා\n",
            "\n",
            "IPA: ɡ ʌ h ʌ n̪ ə ʋ a\n",
            "Expected Sinhala: ගහනවා\n",
            "Got Sinhala: ගහනවා\n",
            "\n",
            "IPA: m ʌ ʈ ə\n",
            "Expected Sinhala: මට\n",
            "Got Sinhala: මට\n",
            "\n",
            "IPA: b ʌ l ʌ n̪ n̪ ə\n",
            "Expected Sinhala: බලන්න\n",
            "Got Sinhala: බලන්න\n",
            "\n",
            "IPA: b ʌ l ʌ n̪ n̪ ʌ | ʌ h ʌ s ə\n",
            "Expected Sinhala: බලන්න අහස\n",
            "Got Sinhala: බලන්න අහස\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "sinhala_word = \"බලන්න අහස\"  # Input Sinhala word\n",
        "ipa_transcription = sinhala_to_ipa(sinhala_word)\n",
        "print(\"Sinhala Word:\", sinhala_word)\n",
        "print(\"IPA Transcription:\", ipa_transcription)"
      ],
      "metadata": {
        "id": "brn84GoSPIn5",
        "outputId": "bcc707d1-8d24-4a0d-b947-cb896d9fba81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sinhala Word: බලන්න අහස\n",
            "IPA Transcription: b ʌ l ʌ n̪ n̪ ʌ | ʌ h ʌ s ə\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset without headers (it doesn't have column names)\n",
        "file_path = '/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict2.csv'\n",
        "df = pd.read_csv(file_path, header=None, names=['word'])\n",
        "\n",
        "# Apply the `sinhala_to_ipa` function to each word\n",
        "df['IPA'] = df['word'].apply(sinhala_to_ipa)\n",
        "\n",
        "# Save the new dataset with 'word' and 'IPA' columns to a new CSV file\n",
        "output_path = '/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict_with_ipa.csv'\n",
        "df[['word', 'IPA']].to_csv(output_path, index=False)\n",
        "\n",
        "print(\"New dataset with IPA has been saved to:\", output_path)\n"
      ],
      "metadata": {
        "id": "It8aB3VyaviM",
        "outputId": "bfb78fd3-e338-4ebf-a0fa-5aca1aa5f5a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New dataset with IPA has been saved to: /content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict_with_ipa.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "nvkfBGildDy7",
        "outputId": "89692b7e-61d2-4520-e71a-a1b17b5e59df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            word                      IPA\n",
              "0      අභිචෝදකයා   ʌ bʱ i ʧ oː d̪ ʌ k ʌ j\n",
              "1          අංකනය          ʌŋ k ʌ n̪ ʌ j ə\n",
              "2           අංකන              ʌŋ k ʌ n̪ ə\n",
              "3           අංකය               ʌŋ k ʌ j ə\n",
              "4      අංකාන්තරය  ʌŋ k aː n̪ t̪ ʌ r ʌ j ə\n",
              "...          ...                      ...\n",
              "67255      හැරීය             h æ r iː j ə\n",
              "67256  හැරීයන්නේ    h æ r iː j ʌ n̪ n̪ eː\n",
              "67257    හැරීයයි         h æ r iː j ʌ j i\n",
              "67258    හැරීයාම        h æ r iː j aː m ə\n",
              "67259   හැරීයොත්          h æ r iː j o t̪\n",
              "\n",
              "[67260 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e85361f-2171-418f-9663-f6894acba8c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>IPA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>අභිචෝදකයා</td>\n",
              "      <td>ʌ bʱ i ʧ oː d̪ ʌ k ʌ j</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>අංකනය</td>\n",
              "      <td>ʌŋ k ʌ n̪ ʌ j ə</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>අංකන</td>\n",
              "      <td>ʌŋ k ʌ n̪ ə</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>අංකය</td>\n",
              "      <td>ʌŋ k ʌ j ə</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>අංකාන්තරය</td>\n",
              "      <td>ʌŋ k aː n̪ t̪ ʌ r ʌ j ə</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67255</th>\n",
              "      <td>හැරීය</td>\n",
              "      <td>h æ r iː j ə</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67256</th>\n",
              "      <td>හැරීයන්නේ</td>\n",
              "      <td>h æ r iː j ʌ n̪ n̪ eː</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67257</th>\n",
              "      <td>හැරීයයි</td>\n",
              "      <td>h æ r iː j ʌ j i</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67258</th>\n",
              "      <td>හැරීයාම</td>\n",
              "      <td>h æ r iː j aː m ə</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67259</th>\n",
              "      <td>හැරීයොත්</td>\n",
              "      <td>h æ r iː j o t̪</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>67260 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e85361f-2171-418f-9663-f6894acba8c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0e85361f-2171-418f-9663-f6894acba8c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0e85361f-2171-418f-9663-f6894acba8c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a0c840b1-65e7-484f-bc63-a31e5d16c0ef\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a0c840b1-65e7-484f-bc63-a31e5d16c0ef')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a0c840b1-65e7-484f-bc63-a31e5d16c0ef button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_654d258a-a743-450f-929f-4d85ccbb0b06\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_654d258a-a743-450f-929f-4d85ccbb0b06 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 67260,\n  \"fields\": [\n    {\n      \"column\": \"word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 67260,\n        \"samples\": [\n          \"\\u0dc3\\u0dd2\\u0dad\\u0d9a\\u0dca\",\n          \"\\u0dc3\\u0dca\\u0db4\\u0dca\\u200d\\u0dba\\u0daf\\u0dca\",\n          \"\\u0dc3\\u0dd8\\u0da2\\u0dd4\\u0dc0\\u0dd3\\u0db8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IPA\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 66898,\n        \"samples\": [\n          \"b \\u028c l \\u028c h \\u028c t\\u032a k a\\u02d0 r \\u0259\",\n          \"h \\u028c j i h \\u028c j i j e n\\u032a\",\n          \"\\u028b i s m i t\\u032a \\u028c \\u028b \\u0259\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def findCorrectWord(dict,ipaWord):\n",
        "  for index, row in dict.iterrows():\n",
        "    if row['IPA'] == ipaWord:\n",
        "      return row['word']"
      ],
      "metadata": {
        "id": "GLxvmO5WxEa7"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import Levenshtein\n",
        "\n",
        "def spell_check(word, dictionary, top_n=3):\n",
        "    # List to store words with their distances\n",
        "    word_distances = []\n",
        "\n",
        "    for correct_word in dictionary:\n",
        "        # Calculate the Levenshtein distance between the word and dictionary word\n",
        "        distance = Levenshtein.distance(word, correct_word)\n",
        "        word_distances.append((correct_word, distance))\n",
        "\n",
        "    # Sort the list by distance (ascending order)\n",
        "    word_distances.sort(key=lambda x: x[1])\n",
        "\n",
        "    # Return the top N closest words\n",
        "    return word_distances[:top_n]\n",
        "\n",
        "def check_sentence(sentence, sinhala_dictionary):\n",
        "    words = sentence.split()  # Split the input sentence into words\n",
        "    corrected_words = []  # List to store corrected words\n",
        "    distances = []  # List to store Levenshtein distances for each word\n",
        "\n",
        "    for word in words:\n",
        "        # Get the top suggestion (closest word) and its distance\n",
        "        top_words = spell_check(sinhala_to_ipa(word), sinhala_dictionary, top_n=3)\n",
        "        if top_words:  # Ensure there's at least one suggestion\n",
        "            corrected_word, distance = top_words[0]  # Top suggestion\n",
        "            corrected_words.append(findCorrectWord(df,corrected_word))  # Add corrected word\n",
        "            distances.append(distance)  # Add the distance\n",
        "        else:\n",
        "            # If no suggestions, append the original word\n",
        "            corrected_words.append(word)\n",
        "            distances.append(None)  # No distance available\n",
        "\n",
        "        print_suggestion(word, top_words)\n",
        "\n",
        "    # Combine corrected words into a single sentence\n",
        "    corrected_sentence = ' '.join(corrected_words)\n",
        "\n",
        "    # Return values\n",
        "    return sentence, corrected_sentence, distances\n",
        "\n",
        "def print_suggestion(word, top_words):\n",
        "    top_words = [(findCorrectWord(df,correct_word), distance) for correct_word, distance in top_words]\n",
        "    print(f\"Suggestions for '{word}':\")\n",
        "    for i, (correct_word, distance) in enumerate(top_words, 1):\n",
        "        print(f\"{i}. {correct_word} (Distance: {distance})\")"
      ],
      "metadata": {
        "id": "PU2YKCXoyzsO"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def load_dictionary(file_path):\n",
        "  df = pd.read_csv(file_path)\n",
        "  return df"
      ],
      "metadata": {
        "id": "d1YGFAI1uUnH"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dictionary from the text file\n",
        "sinhala_dictionary = load_dictionary('/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict_with_ipa.csv')\n",
        "\n",
        "# Input word\n",
        "#sentence = \"මම දනපත දිනපටා ලියනවා\"\n",
        "sentence = \"මම පොත් ලයනවා\"\n",
        "\n",
        "# Perform spell check\n",
        "sentence, corrected_sentence, distances = check_sentence(sentence, sinhala_dictionary['IPA'])\n",
        "print(f\"\\nInput Sentence: {sentence}\")\n",
        "print(f\"Suggested Correction: {corrected_sentence}\")\n",
        "print(f\"Levenshtein Distances: {distances}\")"
      ],
      "metadata": {
        "id": "xO_E-2-JeWKR",
        "outputId": "95929488-5c83-4df5-ac21-4f74aa0af361",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "m ʌ m ə\n",
            "m ʌ m ə\n",
            "ɡ ʌ m ə\n",
            "m ʌ ɖ ə\n",
            "Suggestions for 'මම':\n",
            "1. මම (Distance: 0)\n",
            "2. ගම (Distance: 1)\n",
            "3. මඩ (Distance: 1)\n",
            "p u t̪\n",
            "p u t̪\n",
            "h o t̪\n",
            "s o t̪\n",
            "Suggestions for 'පොත්':\n",
            "1. පුතා (Distance: 1)\n",
            "2. හොත් (Distance: 1)\n",
            "3. සොතා (Distance: 1)\n",
            "ɡ ʌ j ʌ n̪ ə ʋ a\n",
            "ɡ ʌ j ʌ n̪ ə ʋ a\n",
            "l ʌ b ʌ n̪ ə ʋ a\n",
            "l i j ʌ n̪ ə ʋ a\n",
            "Suggestions for 'ලයනවා':\n",
            "1. ගයනවා (Distance: 1)\n",
            "2. ලබනවා (Distance: 1)\n",
            "3. ලියනවා (Distance: 1)\n",
            "\n",
            "Input Sentence: මම පොත් ලයනවා\n",
            "Suggested Correction: මම පුතා ගයනවා\n",
            "Levenshtein Distances: [0, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phenotic encoding"
      ],
      "metadata": {
        "id": "62nFRjqY269D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Sinhala tokennizing"
      ],
      "metadata": {
        "id": "FEHSwPDCtcx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers datasets tokenizers --q"
      ],
      "metadata": {
        "id": "fVo9sXHXti8u"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UwpGSMGXJtIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load the Sinhala-RoBERTa tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"d42kw01f/Sinhala-RoBERTa\")"
      ],
      "metadata": {
        "id": "msRCLJnOJkTA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained('/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_tokenizer')"
      ],
      "metadata": {
        "id": "NAxdPyNscSrP",
        "outputId": "eb7fbaad-1dc4-4330-bee6-4d3dc4c180f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_tokenizer/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_tokenizer/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_tokenizer/vocab.json',\n",
              " '/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_tokenizer/merges.txt',\n",
              " '/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_tokenizer/added_tokens.json',\n",
              " '/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_tokenizer/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: how to use saved tokenizer\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load the saved tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_tokenizer\")\n"
      ],
      "metadata": {
        "id": "o71p9a-acwcl"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Sinhala text example\n",
        "text = \"ඔබේ නම කුමක්ද?\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = tokenizer.tokenize(text)\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "# Convert tokens to input IDs\n",
        "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(\"Input IDs:\", input_ids)\n",
        "\n",
        "# Decode input IDs back to text\n",
        "decoded_text = tokenizer.decode(input_ids)\n",
        "print(\"Decoded Text:\", decoded_text)\n"
      ],
      "metadata": {
        "id": "G7ominpga8lF",
        "outputId": "47a7fc77-760a-4bd0-955a-960373d698fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['à¶Ķà¶¶', 'à·ļ', 'Ġà¶±à¶¸', 'Ġà¶ļ', 'à·Ķ', 'à¶¸à¶ļ', 'à·Ĭ', 'à¶¯', '?']\n",
            "Input IDs: [1704, 277, 364, 281, 272, 361, 264, 283, 35]\n",
            "Decoded Text: ඔබේ නම කුමක්ද?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_text = tokenizer.decode(tokenizer.convert_tokens_to_ids(tokens))\n",
        "print(decoded_text)"
      ],
      "metadata": {
        "id": "SoD-wWBZpTgD",
        "outputId": "3f7ae82d-01a7-43e1-b1da-8f66ce03b505",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ඔබේ නම කුමක්ද?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def load_dictionary(file_path):\n",
        "  df = pd.read_csv(file_path)\n",
        "  return df"
      ],
      "metadata": {
        "id": "TOYB1JEkdp3V"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "import difflib\n",
        "\n",
        "# Example Sinhala dictionary (use your complete dictionary here)\n",
        "sinhala_dict = set([\"අයියා\", \"ආයුබෝවන්\", \"ගමන\", \"කාර්යය\", \"රට\"])\n",
        "\n",
        "# Function to check if a word is in the dictionary\n",
        "def is_word_correct(word, dictionary):\n",
        "    return word in dictionary\n",
        "\n",
        "# Function to suggest correct word based on Levenshtein distance\n",
        "def suggest_correction(word, dictionary):\n",
        "    suggestions = difflib.get_close_matches(word, dictionary, n=3, cutoff=0.6)\n",
        "    return suggestions\n",
        "\n",
        "# Function to perform spell checking\n",
        "def check_spelling(text, tokenizer, dictionary):\n",
        "    # Tokenize the input Sinhala text\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "\n",
        "    # Identify any misspelled words and suggest corrections\n",
        "    misspelled_words = []\n",
        "    corrections = {}\n",
        "\n",
        "    for token in tokens:\n",
        "        word = tokenizer.convert_tokens_to_string([token])\n",
        "\n",
        "        if not is_word_correct(word, dictionary):\n",
        "            misspelled_words.append(word)\n",
        "            corrections[word] = suggest_correction(word, dictionary)\n",
        "\n",
        "    return misspelled_words, corrections\n",
        "\n",
        "# Example input Sinhala text\n",
        "text = \"අයියා මට ගමන කාර්යය.\"\n",
        "\n",
        "# Perform spell checking\n",
        "misspelled_words, corrections = check_spelling(text, tokenizer, sinhala_dict)\n",
        "\n",
        "# Output the results\n",
        "print(\"Misspelled words:\", misspelled_words)\n",
        "print(\"Suggestions:\", corrections)\n"
      ],
      "metadata": {
        "id": "EvWlIW73RLqi",
        "outputId": "d9be30e3-5d4f-423e-827b-07801d03d890",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Misspelled words: ['අය', 'ි', 'ය', 'ා', ' මට', ' ගමන', ' ක', 'ා', 'ර', '්', 'යය', '.']\n",
            "Suggestions: {'අය': [], 'ි': [], 'ය': [], 'ා': [], ' මට': [], ' ගමන': ['ගමන'], ' ක': [], 'ර': ['රට'], '්': [], 'යය': [], '.': []}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load the saved tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_tokenizer\")\n",
        "\n",
        "# Load the dataset without headers (it doesn't have column names)\n",
        "file_path = '/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict2.csv'\n",
        "df = pd.read_csv(file_path, header=None, names=['word'])\n",
        "\n",
        "# Apply the `sinhala_to_ipa` function to each word\n",
        "df['Token'] = df['word'].apply(tokenizer.tokenize)\n",
        "\n",
        "# Save the new dataset with 'word' and 'IPA' columns to a new CSV file\n",
        "output_path = '/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict_tokenize.csv'\n",
        "df[['word', 'Token']].to_csv(output_path, index=False)\n",
        "\n",
        "print(\"New dataset with Token has been saved to:\", output_path)\n"
      ],
      "metadata": {
        "id": "lbd2FDa4iNHr",
        "outputId": "7e30d4c6-3222-404d-a13b-b25ee5a356a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New dataset with Token has been saved to: /content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict_tokenize.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "8PQF1nKr2GLE",
        "outputId": "59b3f9e4-d8be-4202-e28c-405e685cf578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            word                                        Token\n",
              "0      අභිචෝදකයා      [à¶ħà¶·, à·Ĵ, à¶ł, à·Ŀ, à¶¯à¶ļà¶º, à·ı]\n",
              "1          අංකනය                        [à¶ħ, à¶Ĥ, à¶ļà¶±à¶º]\n",
              "2           අංකන                           [à¶ħ, à¶Ĥ, à¶ļà¶±]\n",
              "3           අංකය                           [à¶ħ, à¶Ĥ, à¶ļà¶º]\n",
              "4      අංකාන්තරය    [à¶ħ, à¶Ĥ, à¶ļ, à·ı, à¶±, à·Ĭ, à¶Ńà¶»à¶º]\n",
              "...          ...                                          ...\n",
              "67255      හැරීය                    [à·Ħ, à·Ĳ, à¶», à·ĵ, à¶º]\n",
              "67256  හැරීයන්නේ  [à·Ħ, à·Ĳ, à¶», à·ĵ, à¶ºà¶±, à·Ĭ, à¶±, à·ļ]\n",
              "67257    හැරීයයි            [à·Ħ, à·Ĳ, à¶», à·ĵ, à¶ºà¶º, à·Ĵ]\n",
              "67258    හැරීයාම          [à·Ħ, à·Ĳ, à¶», à·ĵ, à¶º, à·ı, à¶¸]\n",
              "67259   හැරීයොත්     [à·Ħ, à·Ĳ, à¶», à·ĵ, à¶º, à·ľ, à¶Ń, à·Ĭ]\n",
              "\n",
              "[67260 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46c2a7a6-82ea-4120-9fe3-7fc944f6a516\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>Token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>අභිචෝදකයා</td>\n",
              "      <td>[à¶ħà¶·, à·Ĵ, à¶ł, à·Ŀ, à¶¯à¶ļà¶º, à·ı]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>අංකනය</td>\n",
              "      <td>[à¶ħ, à¶Ĥ, à¶ļà¶±à¶º]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>අංකන</td>\n",
              "      <td>[à¶ħ, à¶Ĥ, à¶ļà¶±]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>අංකය</td>\n",
              "      <td>[à¶ħ, à¶Ĥ, à¶ļà¶º]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>අංකාන්තරය</td>\n",
              "      <td>[à¶ħ, à¶Ĥ, à¶ļ, à·ı, à¶±, à·Ĭ, à¶Ńà¶»à¶º]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67255</th>\n",
              "      <td>හැරීය</td>\n",
              "      <td>[à·Ħ, à·Ĳ, à¶», à·ĵ, à¶º]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67256</th>\n",
              "      <td>හැරීයන්නේ</td>\n",
              "      <td>[à·Ħ, à·Ĳ, à¶», à·ĵ, à¶ºà¶±, à·Ĭ, à¶±, à·ļ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67257</th>\n",
              "      <td>හැරීයයි</td>\n",
              "      <td>[à·Ħ, à·Ĳ, à¶», à·ĵ, à¶ºà¶º, à·Ĵ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67258</th>\n",
              "      <td>හැරීයාම</td>\n",
              "      <td>[à·Ħ, à·Ĳ, à¶», à·ĵ, à¶º, à·ı, à¶¸]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67259</th>\n",
              "      <td>හැරීයොත්</td>\n",
              "      <td>[à·Ħ, à·Ĳ, à¶», à·ĵ, à¶º, à·ľ, à¶Ń, à·Ĭ]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>67260 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46c2a7a6-82ea-4120-9fe3-7fc944f6a516')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-46c2a7a6-82ea-4120-9fe3-7fc944f6a516 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-46c2a7a6-82ea-4120-9fe3-7fc944f6a516');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-837d61d8-4dab-46c2-b36b-d8df14a0af9c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-837d61d8-4dab-46c2-b36b-d8df14a0af9c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-837d61d8-4dab-46c2-b36b-d8df14a0af9c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b5484182-9aa8-4c64-b3f9-9e84e35a6b71\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b5484182-9aa8-4c64-b3f9-9e84e35a6b71 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 67260,\n  \"fields\": [\n    {\n      \"column\": \"word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 67260,\n        \"samples\": [\n          \"\\u0dc3\\u0dd2\\u0dad\\u0d9a\\u0dca\",\n          \"\\u0dc3\\u0dca\\u0db4\\u0dca\\u200d\\u0dba\\u0daf\\u0dca\",\n          \"\\u0dc3\\u0dd8\\u0da2\\u0dd4\\u0dc0\\u0dd3\\u0db8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Token\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def findCorrectWord(dict,tokenizeWord):\n",
        "  for index, row in dict.iterrows():\n",
        "    if row['Token'] == tokenizeWord:\n",
        "      return row['word']"
      ],
      "metadata": {
        "id": "PH751ERmoI7-"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import Levenshtein\n",
        "\n",
        "def spell_check(word, dictionary, top_n=3):\n",
        "    # List to store words with their distances\n",
        "    word_distances = []\n",
        "\n",
        "    for correct_word in dictionary:\n",
        "        # Calculate the Levenshtein distance between the word and dictionary word\n",
        "        distance = Levenshtein.distance(word, correct_word)\n",
        "        word_distances.append((correct_word, distance))\n",
        "\n",
        "    # Sort the list by distance (ascending order)\n",
        "    word_distances.sort(key=lambda x: x[1])\n",
        "\n",
        "    # Return the top N closest words\n",
        "    return word_distances[:top_n]\n",
        "\n",
        "def check_sentence(sentence, sinhala_dictionary):\n",
        "    corrected_words = []  # List to store corrected words\n",
        "    distances = []  # List to store Levenshtein distances for each word\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "\n",
        "    for token in tokens:\n",
        "        # Get the top suggestion (closest word) and its distance\n",
        "        decoded_text = tokenizer.decode(tokenizer.convert_tokens_to_ids(token))\n",
        "        top_words = spell_check(token, sinhala_dictionary)\n",
        "        if top_words:  # Ensure there's at least one suggestion\n",
        "            corrected_word, distance = top_words[0]  # Top suggestion\n",
        "            corrected_words.append(findCorrectWord(df,corrected_word))  # Add corrected word\n",
        "            distances.append(distance)  # Add the distance\n",
        "        else:\n",
        "            # If no suggestions, append the original word\n",
        "            corrected_words.append(decoded_text)\n",
        "            distances.append(None)  # No distance available\n",
        "\n",
        "        print_suggestion(decoded_text, top_words)\n",
        "\n",
        "    # Combine corrected words into a single sentence\n",
        "    corrected_sentence = ' '.join(corrected_words)\n",
        "\n",
        "    # Return values\n",
        "    return sentence, corrected_sentence, distances\n",
        "\n",
        "def print_suggestion(word, top_words):\n",
        "    top_words = [(findCorrectWord(df,correct_word), distance) for correct_word, distance in top_words]\n",
        "    print(f\"Suggestions for '{word}':\")\n",
        "    for i, (correct_word, distance) in enumerate(top_words, 1):\n",
        "        print(f\"{i}. {correct_word} (Distance: {distance})\")"
      ],
      "metadata": {
        "id": "OWwuMa6hgCPT"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import Levenshtein\n",
        "\n",
        "def spell_check(word, dictionary, top_n=3):\n",
        "    # List to store words with their distances\n",
        "    word_distances = []\n",
        "\n",
        "    for correct_word in dictionary:\n",
        "        # Calculate the Levenshtein distance between the word and dictionary word\n",
        "        distance = Levenshtein.distance(word, correct_word)\n",
        "        word_distances.append((correct_word, distance))\n",
        "\n",
        "    # Sort the list by distance (ascending order)\n",
        "    word_distances.sort(key=lambda x: x[1])\n",
        "\n",
        "    # Return the top N closest words\n",
        "    return word_distances[:top_n]\n",
        "\n",
        "def check_sentence(sentence, sinhala_dictionary):\n",
        "    words = sentence.split()  # Split the input sentence into words #tokens = tokenizer.tokenize(sentence)\n",
        "    corrected_words = []  # List to store corrected words\n",
        "    distances = []  # List to store Levenshtein distances for each word\n",
        "\n",
        "    for word in words:\n",
        "        # Get the top suggestion (closest word) and its distance\n",
        "        top_words = spell_check(tokenizer.tokenize(word), sinhala_dictionary, top_n=3)\n",
        "        if top_words:  # Ensure there's at least one suggestion\n",
        "            corrected_word, distance = top_words[0]  # Top suggestion\n",
        "            corrected_words.append(findCorrectWord(df,corrected_word))  # Add corrected word\n",
        "            distances.append(distance)  # Add the distance\n",
        "        else:\n",
        "            # If no suggestions, append the original word\n",
        "            corrected_words.append(word)\n",
        "            distances.append(None)  # No distance available\n",
        "\n",
        "        print_suggestion(word, top_words)\n",
        "\n",
        "    # Combine corrected words into a single sentence\n",
        "    corrected_sentence = ' '.join(corrected_words)\n",
        "\n",
        "    # Return values\n",
        "    return sentence, corrected_sentence, distances\n",
        "\n",
        "def print_suggestion(word, top_words):\n",
        "    top_words = [(findCorrectWord(df,correct_word), distance) for correct_word, distance in top_words]\n",
        "    print(f\"Suggestions for '{word}':\")\n",
        "    for i, (correct_word, distance) in enumerate(top_words, 1):\n",
        "        print(f\"{i}. {correct_word} (Distance: {distance})\")"
      ],
      "metadata": {
        "id": "0Gv0AglT3Ktt"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dictionary from the text file\n",
        "sinhala_dictionary = load_dictionary('/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/Datasets/sinhala_dict_tokenize.csv')\n",
        "\n",
        "# Input word\n",
        "#sentence = \"මම දනපත දිනපටා ලියනවා\"\n",
        "sentence = \"මම පොත් ලයනවා\"\n",
        "\n",
        "# Perform spell check\n",
        "sentence, corrected_sentence, distances = check_sentence(sentence, sinhala_dictionary['Token'])\n",
        "print(f\"\\nInput Sentence: {sentence}\")\n",
        "print(f\"Suggested Correction: {corrected_sentence}\")\n",
        "print(f\"Levenshtein Distances: {distances}\")"
      ],
      "metadata": {
        "id": "tdX7v-LMgFkZ",
        "outputId": "ef26649f-72cf-47d4-a95d-46955a69f43c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suggestions for 'මම':\n",
            "1. None (Distance: 7)\n",
            "2. None (Distance: 7)\n",
            "3. None (Distance: 7)\n",
            "Suggestions for 'පොත්':\n",
            "1. None (Distance: 7)\n",
            "2. None (Distance: 7)\n",
            "3. None (Distance: 7)\n",
            "Suggestions for 'ලයනවා':\n",
            "1. None (Distance: 7)\n",
            "2. None (Distance: 7)\n",
            "3. None (Distance: 7)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "sequence item 0: expected str instance, NoneType found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-e680c1ee9bd3>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Perform spell check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrected_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msinhala_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Token'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nInput Sentence: {sentence}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Suggested Correction: {corrected_sentence}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-09ecd4f02b9b>\u001b[0m in \u001b[0;36mcheck_sentence\u001b[0;34m(sentence, sinhala_dictionary)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Combine corrected words into a single sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mcorrected_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrected_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Return values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, NoneType found"
          ]
        }
      ]
    }
  ]
}