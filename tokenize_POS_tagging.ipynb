{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1tJxsUVDTzpAaXjBcRisqzsf718gWR9Ip",
      "authorship_tag": "ABX9TyN0yBUDE4ZzhZRI4P4kbB0O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nuwantha97/Sinhala_spell_and_grammer_checker/blob/Notebooks/tokenize_POS_tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sinling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKDg6e36AEKX",
        "outputId": "93c11db8-dba7-4493-9066-833c8f9e4934"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sinling\n",
            "  Downloading sinling-0.3.6-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting emoji (from sinling)\n",
            "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sinling) (1.4.2)\n",
            "Collecting pygtrie (from sinling)\n",
            "  Downloading pygtrie-2.5.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting sklearn-crfsuite (from sinling)\n",
            "  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sinling) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sinling) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->sinling) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->sinling) (4.67.1)\n",
            "Collecting python-crfsuite>=0.9.7 (from sklearn-crfsuite->sinling)\n",
            "  Downloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->sinling) (1.6.0)\n",
            "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->sinling) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite->sinling) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite->sinling) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite->sinling) (3.5.0)\n",
            "Downloading sinling-0.3.6-py3-none-any.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
            "Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pygtrie, python-crfsuite, emoji, sklearn-crfsuite, sinling\n",
            "Successfully installed emoji-2.14.0 pygtrie-2.5.0 python-crfsuite-0.9.11 sinling-0.3.6 sklearn-crfsuite-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: mount to google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uyzHRz_yAj-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "from typing import List, Tuple, Set, Dict\n",
        "import logging\n",
        "import math\n",
        "import json\n",
        "\n",
        "class SinhalaPOSTagger:\n",
        "    \"\"\"A Part-of-Speech tagger for Sinhala using the Viterbi algorithm.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the Sinhala POS tagger.\"\"\"\n",
        "        self.unknown_prob = math.log(1e-10)\n",
        "        self.bigram_cnt: Dict[Tuple[str, str], int] = defaultdict(int)\n",
        "        self.unigram_cnt: Dict[str, int] = defaultdict(int)\n",
        "        self.tag_count: Dict[str, int] = defaultdict(int)\n",
        "        self.tag_word_count: Counter = Counter()\n",
        "        self.transition_probabilities: Dict[Tuple[str, str], float] = defaultdict(lambda: self.unknown_prob)\n",
        "        self.emission_probabilities: Dict[Tuple[str, str], float] = defaultdict(lambda: self.unknown_prob)\n",
        "        self.states: Set[str] = set()\n",
        "\n",
        "        logging.basicConfig(level=logging.INFO)\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def ngrams(self, text: List[str], n: int) -> List[Tuple[str, ...]]:\n",
        "        \"\"\"Generate n-grams from text.\"\"\"\n",
        "        return [tuple(text[i:i + n]) for i in range(len(text) - n + 1)]\n",
        "\n",
        "    def clean_sinhala(self, word: str) -> str:\n",
        "        \"\"\"Clean Sinhala word and handle Unicode normalization.\n",
        "\n",
        "        Args:\n",
        "            word: Input Sinhala word\n",
        "\n",
        "        Returns:\n",
        "            Cleaned word\n",
        "        \"\"\"\n",
        "        # Remove any whitespace\n",
        "        word = re.sub(r'\\s+', '', word)\n",
        "        # Normalize Zero Width Joiner and Zero Width Non-Joiner\n",
        "        word = re.sub(r'[\\u200D\\u200C]', '', word)\n",
        "        return word\n",
        "\n",
        "    def load_corpus(self, corpus_file: str) -> List[List[Tuple[str, str]]]:\n",
        "        \"\"\"Load Sinhala tagged corpus from file.\n",
        "\n",
        "        Expected format (JSON):\n",
        "        [\n",
        "            [[\"word1\", \"tag1\"], [\"word2\", \"tag2\"]],  # Sentence 1\n",
        "            [[\"word3\", \"tag3\"], [\"word4\", \"tag4\"]]   # Sentence 2\n",
        "        ]\n",
        "        \"\"\"\n",
        "        with open(corpus_file, 'r', encoding='utf-8') as f:\n",
        "            corpus = json.load(f)\n",
        "        return corpus\n",
        "\n",
        "    def train(self, corpus_file: str) -> None:\n",
        "        \"\"\"Train the POS tagger on Sinhala corpus.\n",
        "\n",
        "        Args:\n",
        "            corpus_file: Path to the JSON file containing tagged Sinhala corpus\n",
        "        \"\"\"\n",
        "        self.logger.info(\"Starting training process...\")\n",
        "\n",
        "        corpus = self.load_corpus(corpus_file)\n",
        "        tagged_words = []\n",
        "        all_tags = []\n",
        "\n",
        "        # Process corpus\n",
        "        for sentence in corpus:\n",
        "            all_tags.append(\"START\")\n",
        "            for word, tag in sentence:\n",
        "                if tag and tag not in ['NIL']:\n",
        "                    all_tags.append(tag)\n",
        "                    word = self.clean_sinhala(word)\n",
        "                    tagged_words.append((tag, word))\n",
        "            all_tags.append(\"END\")\n",
        "\n",
        "        # Calculate probabilities\n",
        "        self._calculate_probabilities(tagged_words, all_tags)\n",
        "\n",
        "        self.logger.info(f\"Training complete. Found {len(self.states)} unique tags.\")\n",
        "\n",
        "    def _calculate_probabilities(self, tagged_words: List[Tuple[str, str]], all_tags: List[str]) -> None:\n",
        "        \"\"\"Calculate all probabilities needed for the model.\"\"\"\n",
        "        # Count occurrences\n",
        "        for tag, word in tagged_words:\n",
        "            self.tag_count[tag] += 1\n",
        "            self.tag_word_count[(tag, word)] += 1\n",
        "\n",
        "        # Calculate bigram and unigram counts\n",
        "        for bigram in self.ngrams(all_tags, 2):\n",
        "            self.bigram_cnt[bigram] += 1\n",
        "        for tag in all_tags:\n",
        "            self.unigram_cnt[tag] += 1\n",
        "\n",
        "        # Calculate transition probabilities\n",
        "        for bigram in self.bigram_cnt:\n",
        "            if self.unigram_cnt[bigram[0]] > 0:\n",
        "                prob = self.bigram_cnt[bigram] / self.unigram_cnt[bigram[0]]\n",
        "                self.transition_probabilities[bigram] = math.log(prob) if prob > 0 else self.unknown_prob\n",
        "\n",
        "        # Calculate emission probabilities\n",
        "        for tag, word in tagged_words:\n",
        "            if self.tag_count[tag] > 0:\n",
        "                prob = self.tag_word_count[(tag, word)] / self.tag_count[tag]\n",
        "                self.emission_probabilities[(tag, word)] = math.log(prob) if prob > 0 else self.unknown_prob\n",
        "\n",
        "        # Store states\n",
        "        self.states = set(self.tag_count.keys())\n",
        "\n",
        "    def viterbi(self, observable: List[str], states: Set[str]) -> List[Tuple[str, str]]:\n",
        "        \"\"\"Implement Viterbi algorithm for POS tagging.\"\"\"\n",
        "        if not states:\n",
        "            self.logger.error(\"No states provided for Viterbi algorithm\")\n",
        "            return []\n",
        "\n",
        "        V = [{}]  # Viterbi matrix\n",
        "        path = {}\n",
        "\n",
        "        # Initialize\n",
        "        for state in states:\n",
        "            V[0][state] = (self.transition_probabilities[(\"START\", state)] +\n",
        "                          self.emission_probabilities[(state, observable[0])])\n",
        "            path[state] = [state]\n",
        "\n",
        "        # Run Viterbi\n",
        "        for t in range(1, len(observable)):\n",
        "            V.append({})\n",
        "            newpath = {}\n",
        "\n",
        "            for state in states:\n",
        "                emit_p = self.emission_probabilities[(state, observable[t])]\n",
        "                (prob, state0) = max(\n",
        "                    (V[t-1][y0] + self.transition_probabilities[(y0, state)] + emit_p, y0)\n",
        "                    for y0 in states\n",
        "                )\n",
        "                V[t][state] = prob\n",
        "                newpath[state] = path[state0] + [state]\n",
        "            path = newpath\n",
        "\n",
        "        # Find best path\n",
        "        (prob, state) = max((V[len(observable) - 1][y], y) for y in states)\n",
        "        return list(zip(observable, path[state]))\n",
        "\n",
        "    def tag_sentence(self, sentence: List[str]) -> List[Tuple[str, str]]:\n",
        "        \"\"\"Tag a Sinhala sentence with POS tags.\"\"\"\n",
        "        if not self.states:\n",
        "            self.logger.error(\"Model not trained. Please run train() first.\")\n",
        "            return []\n",
        "\n",
        "        # Tokenize each word in the sentence with error handling\n",
        "        tokenized_words = []\n",
        "        for word in sentence:\n",
        "            if isinstance(word, str):\n",
        "                tokens = tokenizer.tokenize(word)\n",
        "                tokenized_words.append(tokens[0] if tokens else word)\n",
        "            else:\n",
        "                tokenized_words.append(str(word))\n",
        "\n",
        "        cleaned_words = [self.clean_sinhala(w) for w in tokenized_words]\n",
        "        return self.viterbi(cleaned_words, self.states)\n",
        "\n",
        "    def save_model(self, file_path: str) -> None:\n",
        "      \"\"\"Save the trained model to a file.\"\"\"\n",
        "      model_data = {\n",
        "          'bigram_cnt': {\"|\".join(k): v for k, v in self.bigram_cnt.items()},\n",
        "          'unigram_cnt': dict(self.unigram_cnt),\n",
        "          'tag_count': dict(self.tag_count),\n",
        "          'tag_word_count': {\"|\".join(k): v for k, v in self.tag_word_count.items()},\n",
        "          'transition_probabilities': {\"|\".join(k): v for k, v in dict(self.transition_probabilities).items()},\n",
        "          'emission_probabilities': {\"|\".join(k): v for k, v in dict(self.emission_probabilities).items()},\n",
        "          'states': list(self.states)\n",
        "      }\n",
        "\n",
        "      with open(file_path, 'w', encoding='utf-8') as f:\n",
        "          json.dump(model_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    def load_model(self, file_path: str) -> None:\n",
        "        \"\"\"Load a trained model from a file.\"\"\"\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            model_data = json.load(f)\n",
        "\n",
        "        self.bigram_cnt = defaultdict(int, {tuple(k.split(\"|\")): v for k, v in model_data['bigram_cnt'].items()})\n",
        "        self.unigram_cnt = defaultdict(int, model_data['unigram_cnt'])\n",
        "        self.tag_count = defaultdict(int, model_data['tag_count'])\n",
        "        self.tag_word_count = Counter({tuple(k.split(\"|\")): v for k, v in model_data['tag_word_count'].items()})\n",
        "        self.transition_probabilities = defaultdict(\n",
        "            lambda: self.unknown_prob,\n",
        "            {tuple(k.split(\"|\")): v for k, v in model_data['transition_probabilities'].items()}\n",
        "        )\n",
        "        self.emission_probabilities = defaultdict(\n",
        "            lambda: self.unknown_prob,\n",
        "            {tuple(k.split(\"|\")): v for k, v in model_data['emission_probabilities'].items()}\n",
        "        )\n",
        "        self.states = set(model_data['states'])"
      ],
      "metadata": {
        "id": "kbcS3vbpDIWP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/POS data/pos_nod.csv\", on_bad_lines='skip', sep=',', engine='python')\n",
        "\n",
        "# Create a temporary file to store the filtered data\n",
        "with open(\"/content/drive/MyDrive/Projects/Sinhala Spell and Grammer checker/POS data/pos_nod.csv\", 'r', encoding='utf-8') as infile, open('temp.csv', 'w', encoding='utf-8', newline='') as outfile:\n",
        "    reader = csv.reader(infile)\n",
        "    writer = csv.writer(outfile)\n",
        "\n",
        "    for row in reader:\n",
        "        if len(row) <= 2:  # Keep rows with 2 or fewer fields\n",
        "            writer.writerow(row)\n",
        "\n",
        "# Load the modified CSV file into a pandas DataFrame\n",
        "df = pd.read_csv('temp.csv')\n",
        "\n",
        "# prompt: add df to word and tag colunm names\n",
        "\n",
        "df.columns = ['word', 'tag']\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ep5_FytbDYTR",
        "outputId": "b94109ed-9bef-4f5e-f486-971edc953a0c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             word  tag\n",
              "0          මිසයිල  NNJ\n",
              "1         ප්‍රහාර  NNC\n",
              "2           වලින්   CM\n",
              "3      පලස්තීනුවෝ  NNP\n",
              "4               4  NUM\n",
              "...           ...  ...\n",
              "94371   වීරඹුගෙදර  NNP\n",
              "94372     පොතුහැර  NNP\n",
              "94373   බංගලාවත්ත  NNP\n",
              "94374       ලතීෆ්  NNP\n",
              "94375     තව්ෆික්  NNP\n",
              "\n",
              "[94376 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3708ee59-0e8a-4be3-8970-7d67e0309479\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>මිසයිල</td>\n",
              "      <td>NNJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ප්‍රහාර</td>\n",
              "      <td>NNC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>වලින්</td>\n",
              "      <td>CM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>පලස්තීනුවෝ</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>NUM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94371</th>\n",
              "      <td>වීරඹුගෙදර</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94372</th>\n",
              "      <td>පොතුහැර</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94373</th>\n",
              "      <td>බංගලාවත්ත</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94374</th>\n",
              "      <td>ලතීෆ්</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94375</th>\n",
              "      <td>තව්ෆික්</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>94376 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3708ee59-0e8a-4be3-8970-7d67e0309479')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3708ee59-0e8a-4be3-8970-7d67e0309479 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3708ee59-0e8a-4be3-8970-7d67e0309479');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-29aaabc5-5c40-477b-bc58-cba6bba6f535\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-29aaabc5-5c40-477b-bc58-cba6bba6f535')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-29aaabc5-5c40-477b-bc58-cba6bba6f535 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_50117933-ad7e-4129-a758-33d48a974660\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_50117933-ad7e-4129-a758-33d48a974660 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 94376,\n  \"fields\": [\n    {\n      \"column\": \"word\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 31459,\n        \"samples\": [\n          \"\\u0dbb\\u0dcf\\u0da2\\u0db0\\u0dcf\\u0db1\\u0dd2\\u0dba\\u0da7\",\n          \"\\u0db4\\u0dd0\\u0dad\\u0dd4\\u0db8\\u0dca\",\n          \"\\u0db1\\u0ddc\\u0dc0\\u0dda\\u0daf\\u0dd0\\u0dba\\u0dd2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tag\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 35,\n        \"samples\": [\n          \"QUE\",\n          \"NIP\",\n          \"ABB\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: df split to training and test data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'df' is your DataFrame with 'word' and 'tag' columns\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42) # 80% training, 20% testing\n",
        "\n",
        "print(\"Training data size:\", len(train_df))\n",
        "print(\"Testing data size:\", len(test_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3z8MYkxDxRx",
        "outputId": "603ce49c-7a0a-435d-de29-13954235f066"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data size: 75500\n",
            "Testing data size: 18876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sinling import SinhalaTokenizer\n",
        "\n",
        "# Create your training data in JSON format\n",
        "tokenizer = SinhalaTokenizer()\n",
        "\n",
        "# Create your training data in JSON format with tokenized words\n",
        "training_data = []\n",
        "for i in range(len(train_df)):\n",
        "    try:\n",
        "        word = train_df.iloc[i]['word']\n",
        "        if not isinstance(word, str):\n",
        "            continue\n",
        "        # Tokenize the Sinhala word and handle empty results\n",
        "        tokens = tokenizer.tokenize(word)\n",
        "        tokenized_word = tokens[0] if tokens else word\n",
        "        training_data.append([[tokenized_word, train_df.iloc[i]['tag']]])\n",
        "    except (KeyError, IndexError) as e:\n",
        "        print(f\"Skipping row {i}: {e}\")\n",
        "\n",
        "# Save training data to file\n",
        "with open('sinhala_corpus.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(training_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# Create and train the tagger\n",
        "tagger = SinhalaPOSTagger()\n",
        "tagger.train('/content/sinhala_corpus.json')"
      ],
      "metadata": {
        "id": "swfgr2qeD5oH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "tagger.save_model('sinhala_pos_model.json')"
      ],
      "metadata": {
        "id": "QejVaau2D8vf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tag a new sentence\n",
        "sentence = [\"මිනිත්තුවකට\" ,\"තත්පර\" ,\"කීයක්\" ,\"තිබේද\", \"ශ්ස්\"]\n",
        "tagged_sentence = tagger.tag_sentence(sentence)\n",
        "\n",
        "# Print results\n",
        "for word, tag in tagged_sentence:\n",
        "    print(f\"{word}: {tag}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWRzjZNNEABY",
        "outputId": "64941066-4024-4142-b6fe-316c6adddc96"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "මිනිත්තුවකට: NNC\n",
            "තත්පර: VP\n",
            "කීයක්: NNC\n",
            "තිබේද: QBE\n",
            "ශ්ස්: VP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test data evaluvation\n",
        "\n",
        "import json\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the saved model\n",
        "tagger = SinhalaPOSTagger()\n",
        "tagger.load_model('sinhala_pos_model.json')\n",
        "\n",
        "# Prepare test data\n",
        "test_data = []\n",
        "for i in range(len(test_df)):\n",
        "    try:\n",
        "        test_data.append([[test_df.iloc[i]['word'], test_df.iloc[i]['tag']]])\n",
        "    except KeyError:\n",
        "        print(f\"Skipping row {i} due to missing 'word' or 'tag' column\")\n",
        "\n",
        "true_tags = []\n",
        "predicted_tags = []\n",
        "\n",
        "# Evaluate on the test set\n",
        "for sentence in test_data:\n",
        "    for word, tag in sentence:\n",
        "        if not isinstance(word, str):\n",
        "            continue\n",
        "        tokens = tokenizer.tokenize(word)\n",
        "        tokenized_word = tokens[0] if tokens else word\n",
        "        tagged_words = tagger.tag_sentence([tokenized_word])\n",
        "        if tagged_words:\n",
        "            predicted_word, predicted_tag = tagged_words[0]\n",
        "            true_tags.append(tag)\n",
        "            predicted_tags.append(predicted_tag)\n",
        "\n",
        "print(classification_report(true_tags, predicted_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XOHivAL2ALy",
        "outputId": "79fc3872-2578-4896-97ca-809b25b19e19"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ABB       0.93      0.85      0.89        46\n",
            "         AUX       1.00      1.00      1.00        39\n",
            "          CC       1.00      1.00      1.00        28\n",
            "          CM       1.00      0.84      0.91        19\n",
            "         DET       0.96      0.92      0.94        49\n",
            "          FS       1.00      1.00      1.00         2\n",
            "         JCV       0.98      0.92      0.95       159\n",
            "          JJ       1.00      0.94      0.97      1082\n",
            "         NCV       0.96      0.97      0.97       158\n",
            "         NDT       1.00      1.00      1.00        15\n",
            "         NIP       1.00      0.82      0.90        40\n",
            "         NNC       0.94      0.99      0.97      8281\n",
            "        NNC‍       0.99      1.00      0.99        72\n",
            "         NNJ       0.98      0.93      0.96       298\n",
            "        NNNP       1.00      1.00      1.00         1\n",
            "         NNP       0.99      0.95      0.97      3722\n",
            "         NUM       1.00      0.95      0.98       604\n",
            "         NVB       1.00      0.92      0.96       232\n",
            "        POST       0.98      0.93      0.96       218\n",
            "         PRP       1.00      0.98      0.99       127\n",
            "        PUNC       0.83      0.50      0.62        10\n",
            "         QBE       1.00      0.82      0.90        22\n",
            "         QUE       0.65      0.92      0.76        12\n",
            "          RB       0.97      0.99      0.98       133\n",
            "          RP       0.89      0.94      0.92        36\n",
            "       RRPCV       0.98      0.97      0.97        88\n",
            "         UNK       0.98      0.89      0.93       132\n",
            "         URL       1.00      1.00      1.00         1\n",
            "         VFM       0.99      0.93      0.96       530\n",
            "         VNF       0.99      0.93      0.96       783\n",
            "         VNN       0.99      0.97      0.98       830\n",
            "          VP       0.99      0.94      0.96      1107\n",
            "\n",
            "    accuracy                           0.97     18876\n",
            "   macro avg       0.97      0.93      0.95     18876\n",
            "weighted avg       0.97      0.97      0.97     18876\n",
            "\n"
          ]
        }
      ]
    }
  ]
}